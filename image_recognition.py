import customtkinter as ctk
from PIL import Image, ImageTk, ImageDraw, ImageFont
import threading
import os
import importlib.util
import random
import mss
import numpy as np
import tkinter as tk
from tkinter import ttk
import json
import torch
import torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.transforms import functional as F
from torch.utils.data import Dataset, DataLoader
from tkinter import filedialog
from tkinter.messagebox import showinfo, showerror, askyesno
from datetime import datetime
import time
import copy
from typing import List, Dict, Tuple, Optional

import pytesseract

# Import dataset utilities
from dataset_utils import validate_dataset, register_dataset_as_project
# More flexible tesseract path handling
try:
    pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
except:
    pass  # Will use system PATH

# Import device utilities
from device_utils import load_settings, save_settings, get_device, log_cuda_diagnostics, get_cuda_diagnostics

RECOGNIZER_FOLDER = "recognizers"
PROJECTS_FOLDER = "projects"
BOX_COLORS = [
    "#FF5733", "#33FF57", "#3357FF", "#F3FF33", "#FF33E3",
    "#33FFF4", "#FFA533", "#8D33FF", "#33FF8D", "#FF3380"
]

# Annotation types
ANNOTATION_BOX = "box"
ANNOTATION_POLYGON = "polygon"

# Keyboard shortcuts
SHORTCUTS = {
    "save": "<Control-s>",
    "delete": "<Delete>",
    "undo": "<Control-z>",
    "redo": "<Control-y>",
    "next_image": "<Right>",
    "prev_image": "<Left>",
    "zoom_in": "<Control-plus>",
    "zoom_out": "<Control-minus>",
    "reset_zoom": "<Control-0>",
    "pan_mode": "<space>",
    "box_mode": "b",
    "polygon_mode": "p",
    "copy": "<Control-c>",
    "paste": "<Control-v>",
}

def load_font(size):
    try:
        return ImageFont.truetype("arial.ttf", size)
    except:
        return ImageFont.load_default()

class UndoRedoManager:
    """Manages undo/redo operations for annotations"""
    def __init__(self, max_history=50):
        self.history = []
        self.current_index = -1
        self.max_history = max_history
    
    def add_state(self, state):
        """Add a new state to history"""
        # Remove any states after current index
        self.history = self.history[:self.current_index + 1]
        # Add new state
        self.history.append(copy.deepcopy(state))
        # Limit history size
        if len(self.history) > self.max_history:
            self.history.pop(0)
        else:
            self.current_index += 1
    
    def undo(self):
        """Undo to previous state"""
        if self.current_index > 0:
            self.current_index -= 1
            return copy.deepcopy(self.history[self.current_index])
        return None
    
    def redo(self):
        """Redo to next state"""
        if self.current_index < len(self.history) - 1:
            self.current_index += 1
            return copy.deepcopy(self.history[self.current_index])
        return None
    
    def can_undo(self):
        return self.current_index > 0
    
    def can_redo(self):
        return self.current_index < len(self.history) - 1
    
    def clear(self):
        self.history = []
        self.current_index = -1

class ProjectStatistics:
    """Calculate and display project statistics"""
    @staticmethod
    def get_stats(project_path):
        if not project_path or not os.path.exists(project_path):
            return {}
        
        stats = {
            "total_images": 0,
            "annotated_images": 0,
            "total_annotations": 0,
            "classes": {},
            "avg_annotations_per_image": 0
        }
        
        img_dir = os.path.join(project_path, "images")
        ann_dir = os.path.join(project_path, "annotations")
        
        if os.path.exists(img_dir):
            stats["total_images"] = len([f for f in os.listdir(img_dir) 
                                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
        
        if os.path.exists(ann_dir):
            for ann_file in os.listdir(ann_dir):
                if ann_file.endswith('.json'):
                    stats["annotated_images"] += 1
                    with open(os.path.join(ann_dir, ann_file), 'r') as f:
                        data = json.load(f)
                        annotations = data.get('annotations', [])
                        stats["total_annotations"] += len(annotations)
                        for ann in annotations:
                            label = ann.get('label', 'Unknown')
                            stats["classes"][label] = stats["classes"].get(label, 0) + 1
        
        if stats["annotated_images"] > 0:
            stats["avg_annotations_per_image"] = stats["total_annotations"] / stats["annotated_images"]
        
        return stats

class RecognizerManager:
    def __init__(self, folder):
        self.folder = folder
        self.recognizers = self.load_recognizers()

    def load_recognizers(self):
        modules = {}
        for fname in os.listdir(self.folder):
            if fname.endswith(".py") and not fname.startswith("_"):
                path = os.path.join(self.folder, fname)
                spec = importlib.util.spec_from_file_location(fname[:-3], path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                if hasattr(module, "Recognizer"):
                    modules[fname[:-3]] = module.Recognizer()
        return modules

    def get_names(self):
        return list(self.recognizers.keys())

    def recognize(self, name, image_np):
        return self.recognizers[name].recognize(image_np)

class ResultListBox(ctk.CTkFrame):
    def __init__(self, master, callback_highlight, callback_delete=None, *args, **kwargs):
        super().__init__(master, *args, **kwargs)
        self.scrollbar = ctk.CTkScrollbar(self)
        self.scrollbar.pack(side="right", fill="y")
        self.listbox = tk.Listbox(self, activestyle="none", height=7, font=("Segoe UI", 12))
        self.listbox.pack(side="left", fill="both", expand=True)
        self.listbox.config(yscrollcommand=self.scrollbar.set)
        self.scrollbar.configure(command=self.listbox.yview)
        self.callback_highlight = callback_highlight
        self.callback_delete = callback_delete
        self.listbox.bind("<<ListboxSelect>>", self.on_select)

    def update_results(self, results):
        self.listbox.delete(0, tk.END)
        for idx, r in enumerate(results):
            label = r.get("label", "Unknown")
            score = r.get("score", None)
            s = f"{label}"
            if score is not None and isinstance(score, float):
                s += f" ({score*100:.1f}%)"
            self.listbox.insert(tk.END, s)

    def on_select(self, e):
        sel = self.listbox.curselection()
        if sel:
            self.callback_highlight(sel[0])
        else:
            self.callback_highlight(None)

    def clear_selection(self):
        self.listbox.selection_clear(0, tk.END)

class AnnotationDataset(Dataset):
    def __init__(self, project_path, class_to_id):
        self.img_dir = os.path.join(project_path, "images")
        self.ann_dir = os.path.join(project_path, "annotations")
        self.imgs = [f for f in os.listdir(self.img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        self.class_to_id = class_to_id

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        img_name = self.imgs[idx]
        img_path = os.path.join(self.img_dir, img_name)
        ann_name = os.path.splitext(img_name)[0] + '.json'
        ann_path = os.path.join(self.ann_dir, ann_name)
        if not os.path.exists(ann_path):
            return None, None

        img = Image.open(img_path).convert("RGB")
        with open(ann_path, 'r') as f:
            data = json.load(f)

        boxes = []
        labels = []
        # Support both per-image format (detections key) and project format (annotations key)
        annotations = data.get('annotations', data.get('detections', []))
        for ann in annotations:
            box = ann.get('box')
            label = ann.get('label')
            if box and label in self.class_to_id:
                boxes.append(box)
                labels.append(self.class_to_id[label])

        if not boxes:
            return None, None

        boxes = torch.as_tensor(boxes, dtype=torch.float32)
        labels = torch.as_tensor(labels, dtype=torch.int64)
        image_id = torch.tensor([idx])
        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])
        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)

        target = {
            "boxes": boxes,
            "labels": labels,
            "image_id": image_id,
            "area": area,
            "iscrowd": iscrowd
        }

        img = F.to_tensor(img)
        return img, target

class ImageRecognitionApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Image Labeling Studio Pro")
        self.geometry("1500x950")
        ctk.set_appearance_mode("Dark")
        ctk.set_default_color_theme("blue")
        
        # Load application settings
        self.settings = load_settings()
        
        # Auto-save settings
        self.auto_save_enabled = True
        self.last_save_time = None
        
        # Device settings for training
        self.detect_device()
        self.device_preference = self.settings.get('device_preference', 'auto')
        
        # Live recognition settings
        self.live_recognition_active = False
        self.live_capture_thread = None
        self.live_fps = 3
        self.live_frames_to_save = 10

        if not os.path.exists(RECOGNIZER_FOLDER):
            os.makedirs(RECOGNIZER_FOLDER)
        if not os.path.exists(PROJECTS_FOLDER):
            os.makedirs(PROJECTS_FOLDER)

        self.recognizer_manager = RecognizerManager(RECOGNIZER_FOLDER)
        self.current_project = None
        self.classes = []
        self.current_image_path = None
        self.original_image = None
        self.annotations = []
        self.drawing = False
        self.rect = None
        self.highlighted_box_idx = None
        self.displayed_w = 0
        self.displayed_h = 0
        self.img_left = 0
        self.img_top = 0
        
        # New features
        self.undo_manager = UndoRedoManager()
        self.annotation_mode = ANNOTATION_BOX  # "box" or "polygon"
        self.polygon_points = []
        self.temp_polygon_items = []
        self.zoom_level = 1.0
        self.pan_offset = [0, 0]
        self.panning = False
        self.pan_start = None
        self.clipboard_annotations = []
        self.image_list = []
        self.current_image_index = -1
        self.show_tooltips = True
        self.training_progress = 0
        self.training_metrics = {"loss": [], "epoch": 0}
        
        # Recognition settings
        self.confidence_threshold = 0.5
        self.iou_threshold = 0.5
        self.nms_enabled = True

        # Project bar with stats - Enhanced styling
        self.project_frame = ctk.CTkFrame(self, height=65, corner_radius=10)
        self.project_frame.pack(fill="x", padx=10, pady=8)
        
        # Left side - Project controls
        left_controls = ctk.CTkFrame(self.project_frame, fg_color="transparent")
        left_controls.pack(side="left", fill="both", expand=False, padx=8, pady=8)
        
        ctk.CTkLabel(left_controls, text="üìÅ Project:", 
                    font=ctk.CTkFont(size=13, weight="bold")).pack(side="left", padx=5)
        self.project_label = ctk.CTkLabel(left_controls, text="None", 
                                         font=ctk.CTkFont(size=12),
                                         text_color="#3498DB")
        self.project_label.pack(side="left", padx=5)
        self.new_project_button = ctk.CTkButton(left_controls, text="‚ûï New", 
                                                command=self.new_project, width=90,
                                                height=32, corner_radius=8)
        self.new_project_button.pack(side="left", padx=3)
        self.open_project_button = ctk.CTkButton(left_controls, text="üìÇ Open", 
                                                 command=self.open_project, width=90,
                                                 height=32, corner_radius=8)
        self.open_project_button.pack(side="left", padx=3)
        self.import_button = ctk.CTkButton(left_controls, text="üì• Import", 
                                          command=self.import_annotations, width=85,
                                          height=32, corner_radius=8)
        self.import_button.pack(side="left", padx=3)
        self.export_button = ctk.CTkButton(left_controls, text="üì§ Export", 
                                          command=self.export_annotations, width=85,
                                          height=32, corner_radius=8)
        self.export_button.pack(side="left", padx=3)
        
        # Right side - Statistics
        self.stats_frame = ctk.CTkFrame(self.project_frame, fg_color="transparent")
        self.stats_frame.pack(side="right", fill="both", expand=False, padx=8, pady=8)
        self.stats_label = ctk.CTkLabel(self.stats_frame, text="üìä No project loaded", 
                                        font=ctk.CTkFont(size=12),
                                        text_color="#95A5A6")
        self.stats_label.pack(side="right", padx=5)

        # Tabview
        self.tabview = ctk.CTkTabview(self)
        self.tabview.pack(fill="both", expand=True, padx=10, pady=5)

        self.setup_recognize_tab()
        self.setup_label_tab()
        self.setup_train_tab()
        self.setup_dashboard_tab()

        self.reload_recognizers()
        self.setup_keyboard_shortcuts()
        self.setup_menu_bar()
        self.setup_status_bar()
        self.show_onboarding()

    def detect_device(self):
        """Detect CUDA availability and set device"""
        try:
            # Log comprehensive CUDA diagnostics at startup
            print("\n" + "=" * 60)
            print("Application Startup - CUDA Detection")
            print("=" * 60)
            log_cuda_diagnostics(print)
            
            if torch.cuda.is_available():
                self.detected_device = 'cuda'
                self.device_name = f"CUDA ({torch.cuda.get_device_name(0)})"
            else:
                self.detected_device = 'cpu'
                self.device_name = 'CPU'
        except Exception as e:
            print(f"Error detecting device: {e}")
            self.detected_device = 'cpu'
            self.device_name = 'CPU (fallback)'
    
    def get_training_device(self):
        """Get device for training based on preference setting"""
        device, device_name, warning = get_device(self.device_preference)
        
        if warning:
            print(f"Warning: {warning}")
            self.show_notification(f"‚ö†Ô∏è {warning}", "warning")
        
        return device, device_name
    
    def save_device_preference(self, preference):
        """Save device preference to settings"""
        self.device_preference = preference
        self.settings['device_preference'] = preference
        save_settings(self.settings)
        self.update_detected_device_display()
    
    def update_detected_device_display(self):
        """Update the detected device display in Training tab"""
        if hasattr(self, 'detected_device_label'):
            device, device_name, warning = get_device(self.device_preference)
            if warning:
                display_text = f"Detected: {self.device_name} | ‚ö†Ô∏è {warning}"
                self.detected_device_label.configure(text=display_text, text_color="#E67E22")
            else:
                display_text = f"Detected: {self.device_name}"
                self.detected_device_label.configure(text=display_text, text_color="#95A5A6")
    
    def show_cuda_diagnostics(self):
        """Show comprehensive CUDA diagnostics dialog"""
        dialog = ctk.CTkToplevel(self)
        dialog.title("CUDA Diagnostics")
        dialog.geometry("700x600")
        dialog.grab_set()
        
        ctk.CTkLabel(dialog, text="üîç CUDA System Diagnostics", 
                    font=ctk.CTkFont(size=20, weight="bold")).pack(pady=15)
        
        # Get diagnostics
        diagnostics = get_cuda_diagnostics()
        
        # Create scrollable text widget
        text_frame = ctk.CTkFrame(dialog)
        text_frame.pack(pady=10, padx=20, fill="both", expand=True)
        
        text = ctk.CTkTextbox(text_frame, width=650, height=450, 
                             font=("Consolas", 11))
        text.pack(pady=5, padx=5, fill="both", expand=True)
        
        # Build diagnostic output
        output = []
        output.append("=" * 60)
        output.append("SYSTEM INFORMATION")
        output.append("=" * 60)
        output.append(f"PyTorch version: {diagnostics['torch_version']}")
        output.append(f"CUDA version: {diagnostics['cuda_version']}")
        output.append(f"Python executable: {diagnostics['python_executable']}")
        output.append("")
        output.append("=" * 60)
        output.append("CUDA STATUS")
        output.append("=" * 60)
        output.append(f"CUDA available: {diagnostics['cuda_available']}")
        output.append(f"CUDA device count: {diagnostics['device_count']}")
        
        if diagnostics['device_name']:
            output.append(f"Device name: {diagnostics['device_name']}")
        
        output.append(f"CUDA_VISIBLE_DEVICES: {diagnostics['cuda_visible_devices']}")
        output.append("")
        
        # Add status-specific information
        if diagnostics['cuda_available']:
            output.append("‚úì CUDA is working correctly!")
            output.append("")
            output.append("Your system is ready for GPU-accelerated training.")
            output.append("Select 'Auto' or 'Force GPU' in device settings to use GPU.")
        else:
            output.append("‚ö†Ô∏è CUDA NOT DETECTED")
            output.append("")
            output.append("=" * 60)
            output.append("TROUBLESHOOTING STEPS")
            output.append("=" * 60)
            output.append("")
            
            if diagnostics['cuda_version'] is None:
                output.append("Issue: CPU-only PyTorch Installation")
                output.append("")
                output.append("Your PyTorch installation does NOT have CUDA support.")
                output.append("You are using a CPU-only version.")
                output.append("")
                output.append("Solution:")
                output.append("1. Visit https://pytorch.org/get-started/locally/")
                output.append("2. Select your OS, Package Manager, Python version, and CUDA version")
                output.append("3. Run the installation command provided")
                output.append("")
                output.append("Example for CUDA 12.1:")
                output.append("  pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121")
            else:
                output.append("Issue: CUDA not detected despite PyTorch CUDA support")
                output.append("")
                output.append("Possible causes:")
                output.append("")
                output.append("1. No NVIDIA GPU in system")
                output.append("   - Check if you have an NVIDIA GPU")
                output.append("   - Run 'nvidia-smi' in terminal to verify")
                output.append("")
                output.append("2. NVIDIA drivers not installed or outdated")
                output.append("   - Download latest drivers from nvidia.com")
                output.append(f"   - Your PyTorch expects CUDA {diagnostics['cuda_version']}")
                output.append("   - Driver version must support this CUDA version")
                output.append("")
                output.append("3. CUDA_VISIBLE_DEVICES environment variable issue")
                output.append(f"   - Current value: {diagnostics['cuda_visible_devices']}")
                output.append("   - If set to -1 or empty, GPUs are hidden")
                output.append("   - Unset it or set to valid GPU IDs (0,1,2...)")
                output.append("")
                output.append("4. Incompatible CUDA/driver version")
                output.append("   - Run 'nvidia-smi' to check driver version")
                output.append("   - Ensure driver supports CUDA version in PyTorch")
                output.append("")
                output.append("Verification commands:")
                output.append("  nvidia-smi          # Check GPU and driver")
                output.append("  nvcc --version      # Check CUDA toolkit")
            
            output.append("")
            output.append("Note: Training will use CPU (slower but functional)")
        
        output.append("")
        output.append("=" * 60)
        
        # Insert text
        text.insert("1.0", "\n".join(output))
        text.configure(state="disabled")
        
        # Store output for clipboard
        self._cuda_diagnostics_output = "\n".join(output)
        
        # Buttons frame
        btn_frame = ctk.CTkFrame(dialog, fg_color="transparent")
        btn_frame.pack(pady=10)
        
        # Copy to clipboard button
        def copy_to_clipboard():
            self.clipboard_clear()
            self.clipboard_append(self._cuda_diagnostics_output)
            copy_btn.configure(text="‚úì Copied!")
            self.after(2000, lambda: copy_btn.configure(text="üìã Copy to Clipboard"))
        
        copy_btn = ctk.CTkButton(btn_frame, text="üìã Copy to Clipboard", 
                                command=copy_to_clipboard,
                                width=160, height=35,
                                font=ctk.CTkFont(size=12))
        copy_btn.pack(side="left", padx=5)
        
        # Close button
        ctk.CTkButton(btn_frame, text="Close", command=dialog.destroy,
                     width=100, height=35,
                     font=ctk.CTkFont(size=12)).pack(side="left", padx=5)
    
    def setup_status_bar(self):
        """Setup status bar at bottom of window"""
        self.status_bar = ctk.CTkFrame(self, height=32, corner_radius=0)
        self.status_bar.pack(side="bottom", fill="x", padx=0, pady=0)
        
        # Device indicator
        device_text = f"üñ•Ô∏è Device: {self.device_name}"
        self.device_label = ctk.CTkLabel(self.status_bar, text=device_text, 
                                         font=ctk.CTkFont(size=11),
                                         text_color="#95A5A6")
        self.device_label.pack(side="left", padx=10, pady=5)
        
        # Status message
        self.status_message = ctk.CTkLabel(self.status_bar, text="Ready", 
                                          font=ctk.CTkFont(size=11),
                                          text_color="#95A5A6")
        self.status_message.pack(side="left", padx=20, pady=5)
    
    def show_notification(self, message, msg_type="info"):
        """Show notification in status bar"""
        colors = {
            "info": "#3498DB",
            "success": "#2ECC71",
            "warning": "#E67E22",
            "error": "#E74C3C"
        }
        if hasattr(self, 'status_message'):
            self.status_message.configure(text=message, text_color=colors.get(msg_type, "#95A5A6"))
    
    def setup_recognize_tab(self):
        tab = self.tabview.add("Recognize")
        tab.columnconfigure(1, weight=1)
        tab.rowconfigure(0, weight=1)

        # Left panel
        left_panel = ctk.CTkFrame(tab, width=230)
        left_panel.grid(row=0, column=0, sticky="ns", padx=10, pady=10)
        left_panel.grid_propagate(False)

        ctk.CTkLabel(left_panel, text="ü§ñ Recognizers", 
                    font=ctk.CTkFont(size=16, weight="bold")).pack(pady=(15, 8))
        names = self.recognizer_manager.get_names()
        self.selected_recognizer = ctk.StringVar(value=names[0] if names else "")
        self.recognizer_menu = ctk.CTkOptionMenu(left_panel, variable=self.selected_recognizer, 
                                                 values=names, height=32, 
                                                 font=ctk.CTkFont(size=12))
        self.recognizer_menu.pack(pady=6, padx=10, fill="x")
        
        # Detection settings
        ctk.CTkLabel(left_panel, text="‚öôÔ∏è Detection Settings", 
                    font=ctk.CTkFont(size=15, weight="bold")).pack(pady=(15, 8))
        
        # Confidence threshold
        conf_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        conf_frame.pack(pady=5, padx=10, fill="x")
        ctk.CTkLabel(conf_frame, text="Confidence:", 
                    font=ctk.CTkFont(size=12)).pack(side="left")
        self.confidence_label = ctk.CTkLabel(conf_frame, text=f"{self.confidence_threshold:.2f}", 
                                             width=45,
                                             font=ctk.CTkFont(size=12, weight="bold"),
                                             text_color="#3498DB")
        self.confidence_label.pack(side="right")
        self.confidence_slider = ctk.CTkSlider(left_panel, from_=0.1, to=0.95, number_of_steps=17,
                                               command=self.update_confidence_threshold,
                                               height=18, button_length=20)
        self.confidence_slider.set(self.confidence_threshold)
        self.confidence_slider.pack(pady=4, padx=10, fill="x")
        
        # NMS toggle
        self.nms_var = tk.BooleanVar(value=True)
        ctk.CTkCheckBox(left_panel, text="Remove Duplicates (NMS)", 
                       variable=self.nms_var,
                       font=ctk.CTkFont(size=11)).pack(pady=5)
        
        # Live recognition section
        ctk.CTkLabel(left_panel, text="üé• Live Mode", 
                    font=ctk.CTkFont(size=15, weight="bold")).pack(pady=(15, 8))
        
        self.live_mode_var = tk.BooleanVar(value=False)
        self.live_mode_checkbox = ctk.CTkCheckBox(left_panel, text="Enable Live Recognition", 
                                                   variable=self.live_mode_var,
                                                   command=self.toggle_live_mode,
                                                   font=ctk.CTkFont(size=12))
        self.live_mode_checkbox.pack(pady=5)
        
        # FPS control
        fps_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        fps_frame.pack(pady=5, padx=10, fill="x")
        ctk.CTkLabel(fps_frame, text="FPS:", 
                    font=ctk.CTkFont(size=11)).pack(side="left")
        self.fps_label = ctk.CTkLabel(fps_frame, text=f"{self.live_fps}", 
                                      width=30,
                                      font=ctk.CTkFont(size=11, weight="bold"),
                                      text_color="#3498DB")
        self.fps_label.pack(side="right")
        self.fps_slider = ctk.CTkSlider(left_panel, from_=1, to=10, number_of_steps=9,
                                        command=self.update_fps,
                                        height=16, button_length=18)
        self.fps_slider.set(self.live_fps)
        self.fps_slider.pack(pady=4, padx=10, fill="x")
        
        # Frames to save control
        frames_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        frames_frame.pack(pady=5, padx=10, fill="x")
        ctk.CTkLabel(frames_frame, text="Save frames:", 
                    font=ctk.CTkFont(size=11)).pack(side="left")
        self.frames_entry = ctk.CTkEntry(frames_frame, width=60, 
                                         font=ctk.CTkFont(size=11))
        self.frames_entry.insert(0, str(self.live_frames_to_save))
        self.frames_entry.pack(side="right")

        self.rec_capture_button = ctk.CTkButton(left_panel, text="üì∏ Capture & Recognize", 
                                                command=self.rec_capture_and_recognize_thread,
                                                font=ctk.CTkFont(size=14, weight="bold"),
                                                height=40, corner_radius=10,
                                                fg_color="#3498DB", hover_color="#2980B9")
        self.rec_capture_button.pack(pady=15, padx=10, fill="x")

        self.rec_status_label = ctk.CTkLabel(left_panel, text="Ready", text_color="gray")
        self.rec_status_label.pack(pady=(0, 15))

        ctk.CTkLabel(left_panel, text="üìä Results", 
                    font=ctk.CTkFont(size=16, weight="bold")).pack(pady=(12, 6))
        self.rec_result_panel = ResultListBox(left_panel, self.rec_highlight_box)
        self.rec_result_panel.pack(fill="x", padx=10, pady=(0, 12))

        # Save options
        ctk.CTkLabel(left_panel, text="üíæ Export", 
                    font=ctk.CTkFont(size=15, weight="bold")).pack(pady=(12, 6))
        
        # Annotation format selector
        format_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        format_frame.pack(pady=5, padx=10, fill="x")
        ctk.CTkLabel(format_frame, text="Format:", 
                    font=ctk.CTkFont(size=11)).pack(side="left")
        self.save_format_var = tk.StringVar(value="COCO JSON")
        self.format_menu = ctk.CTkOptionMenu(format_frame, variable=self.save_format_var,
                                            values=["COCO JSON", "Per-image JSON"],
                                            width=130, height=28,
                                            font=ctk.CTkFont(size=10))
        self.format_menu.pack(side="right")
        
        self.rec_save_button = ctk.CTkButton(left_panel, text="üíæ Save Images + Annotations", 
                                             command=self.rec_save_images_with_annotations,
                                             height=36, corner_radius=8,
                                             font=ctk.CTkFont(size=12, weight="bold"),
                                             fg_color="#27AE60", hover_color="#229954")
        self.rec_save_button.pack(pady=5, padx=10, fill="x")

        self.rec_copy_button = ctk.CTkButton(left_panel, text="üìã Copy Labels", 
                                             command=self.rec_copy_labels,
                                             height=32, corner_radius=8,
                                             font=ctk.CTkFont(size=11))
        self.rec_copy_button.pack(pady=5, padx=10, fill="x")

        # Image frame
        image_frame = ctk.CTkFrame(tab)
        image_frame.grid(row=0, column=1, sticky="nsew")
        image_frame.rowconfigure(0, weight=1)
        image_frame.columnconfigure(0, weight=1)

        self.rec_canvas = tk.Canvas(image_frame, bg="black", highlightthickness=0)
        self.rec_canvas.grid(row=0, column=0, sticky="nsew")
        self.rec_canvas.bind("<Configure>", self.rec_on_canvas_resize)

        self.rec_last_image = None
        self.rec_last_results = []
        self.rec_image_on_canvas = None

    def setup_label_tab(self):
        tab = self.tabview.add("Label")
        tab.columnconfigure(1, weight=1)
        tab.rowconfigure(0, weight=1)

        # Left panel with scrollbar
        left_panel = ctk.CTkFrame(tab, width=280)
        left_panel.grid(row=0, column=0, sticky="ns", padx=10, pady=10)
        left_panel.grid_propagate(False)

        # Annotation mode selector - Enhanced
        ctk.CTkLabel(left_panel, text="üé® Annotation Mode", 
                    font=ctk.CTkFont(size=16, weight="bold")).pack(pady=(12, 6))
        mode_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        mode_frame.pack(pady=5)
        self.mode_var = tk.StringVar(value=ANNOTATION_BOX)
        ctk.CTkRadioButton(mode_frame, text="‚ñ° Box (B)", variable=self.mode_var, 
                          value=ANNOTATION_BOX, command=self.change_annotation_mode,
                          font=ctk.CTkFont(size=12)).pack(anchor="w", padx=10, pady=2)
        ctk.CTkRadioButton(mode_frame, text="‚¨° Polygon (P)", variable=self.mode_var, 
                          value=ANNOTATION_POLYGON, command=self.change_annotation_mode,
                          font=ctk.CTkFont(size=12)).pack(anchor="w", padx=10, pady=2)

        # Classes section - Enhanced
        ctk.CTkLabel(left_panel, text="üè∑Ô∏è Classes", 
                    font=ctk.CTkFont(size=16, weight="bold")).pack(pady=(12, 6))
        self.add_class_button = ctk.CTkButton(left_panel, text="‚ûï Add Class", 
                                              command=self.add_class, width=140,
                                              height=32, corner_radius=8,
                                              font=ctk.CTkFont(size=12))
        self.add_class_button.pack(pady=5)

        self.classes_listbox = tk.Listbox(left_panel, height=5)
        self.classes_listbox.pack(fill="x", padx=5, pady=4)

        # Image navigation - Enhanced
        ctk.CTkLabel(left_panel, text="üñºÔ∏è Navigation", 
                    font=ctk.CTkFont(size=16, weight="bold")).pack(pady=(12, 6))
        nav_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        nav_frame.pack(pady=5)
        ctk.CTkButton(nav_frame, text="‚óÄ", command=self.prev_image, width=50,
                     height=32, corner_radius=8).pack(side="left", padx=2)
        self.image_counter_label = ctk.CTkLabel(nav_frame, text="0/0", width=60,
                                                font=ctk.CTkFont(size=13, weight="bold"))
        self.image_counter_label.pack(side="left", padx=5)
        ctk.CTkButton(nav_frame, text="‚ñ∂", command=self.next_image, width=50,
                     height=32, corner_radius=8).pack(side="left", padx=2)
        
        btn_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        btn_frame.pack(pady=2)
        self.lab_capture_button = ctk.CTkButton(btn_frame, text="üì∑ Capture", command=self.lab_capture_image_thread, width=130)
        self.lab_capture_button.pack(side="left", padx=2)
        self.lab_load_button = ctk.CTkButton(btn_frame, text="üìÅ Load", command=self.lab_load_image, width=130)
        self.lab_load_button.pack(side="left", padx=2)

        # Zoom controls - Enhanced
        zoom_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        zoom_frame.pack(pady=5)
        ctk.CTkButton(zoom_frame, text="+", command=self.zoom_in, width=45,
                     height=32, corner_radius=8).pack(side="left", padx=2)
        ctk.CTkButton(zoom_frame, text="‚àí", command=self.zoom_out, width=45,
                     height=32, corner_radius=8).pack(side="left", padx=2)
        ctk.CTkButton(zoom_frame, text="100%", command=self.reset_zoom, width=55,
                     height=32, corner_radius=8).pack(side="left", padx=2)
        self.zoom_label = ctk.CTkLabel(zoom_frame, text="100%", width=50,
                                       font=ctk.CTkFont(size=12, weight="bold"),
                                       text_color="#3498DB")
        self.zoom_label.pack(side="left", padx=3)

        self.lab_status_label = ctk.CTkLabel(left_panel, text="Ready", text_color="gray")
        self.lab_status_label.pack(pady=4)

        # Annotations section - Enhanced
        ctk.CTkLabel(left_panel, text="üìù Annotations", 
                    font=ctk.CTkFont(size=16, weight="bold")).pack(pady=(12, 6))
        self.lab_result_panel = ResultListBox(left_panel, self.lab_highlight_box)
        self.lab_result_panel.pack(fill="both", expand=True, padx=5, pady=(0, 8))

        # Batch operations
        batch_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        batch_frame.pack(pady=2)
        ctk.CTkButton(batch_frame, text="Copy", command=self.copy_annotations, width=85).pack(side="left", padx=2)
        ctk.CTkButton(batch_frame, text="Paste", command=self.paste_annotations, width=85).pack(side="left", padx=2)

        action_frame = ctk.CTkFrame(left_panel, fg_color="transparent")
        action_frame.pack(pady=2)
        ctk.CTkButton(action_frame, text="Undo", command=self.undo, width=60).pack(side="left", padx=2)
        ctk.CTkButton(action_frame, text="Redo", command=self.redo, width=60).pack(side="left", padx=2)
        self.lab_delete_button = ctk.CTkButton(action_frame, text="Delete", command=self.lab_delete_selected, width=80)
        self.lab_delete_button.pack(side="left", padx=2)

        # Auto-save toggle
        self.auto_save_var = tk.BooleanVar(value=True)
        ctk.CTkCheckBox(left_panel, text="Auto-save on image change", 
                       variable=self.auto_save_var).pack(pady=3)
        
        self.lab_save_button = ctk.CTkButton(left_panel, text="üíæ Save Annotations", 
                                            command=self.lab_save_annotations, 
                                            fg_color="green", hover_color="darkgreen",
                                            font=ctk.CTkFont(size=13, weight="bold"))
        self.lab_save_button.pack(pady=8, fill="x", padx=5)

        # Image frame
        image_frame = ctk.CTkFrame(tab)
        image_frame.grid(row=0, column=1, sticky="nsew")
        image_frame.rowconfigure(0, weight=1)
        image_frame.columnconfigure(0, weight=1)

        self.lab_canvas = tk.Canvas(image_frame, bg="#0D1117", highlightthickness=0, cursor="crosshair")
        self.lab_canvas.grid(row=0, column=0, sticky="nsew")
        self.lab_canvas.bind("<Configure>", self.lab_on_canvas_resize)
        self.lab_canvas.bind("<Button-1>", self.lab_on_mouse_down)
        self.lab_canvas.bind("<B1-Motion>", self.lab_on_mouse_move)
        self.lab_canvas.bind("<ButtonRelease-1>", self.lab_on_mouse_up)
        self.lab_canvas.bind("<Button-3>", self.lab_on_right_click)  # Right-click for polygon
        self.lab_canvas.bind("<Button-2>", self.lab_start_pan)  # Middle-click for pan
        self.lab_canvas.bind("<B2-Motion>", self.lab_pan_move)
        self.lab_canvas.bind("<ButtonRelease-2>", self.lab_end_pan)
        self.lab_canvas.bind("<MouseWheel>", self.lab_on_mousewheel)  # Scroll for zoom
        self.lab_canvas.bind("<Motion>", self.lab_on_mouse_motion)  # Track mouse for preview

        self.lab_image_on_canvas = None
        self.preview_rect = None
        self.mouse_x = 0
        self.mouse_y = 0

    def setup_train_tab(self):
        tab = self.tabview.add("Train")
        tab.columnconfigure(0, weight=1)
        tab.rowconfigure(0, weight=1)

        # Main container with two columns
        main_frame = ctk.CTkFrame(tab)
        main_frame.grid(row=0, column=0, sticky="nsew", padx=20, pady=20)
        main_frame.columnconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)

        # Left side - Training Settings
        left_frame = ctk.CTkFrame(main_frame)
        left_frame.grid(row=0, column=0, sticky="nsew", padx=10, pady=10)

        ctk.CTkLabel(left_frame, text="Training Configuration", 
                    font=ctk.CTkFont(size=20, weight="bold")).pack(pady=15)

        # Intelligent auto-settings button
        auto_btn = ctk.CTkButton(left_frame, text="üß† Auto-Configure Settings", 
                                command=self.apply_intelligent_settings,
                                fg_color="#9B59B6", hover_color="#8E44AD",
                                font=ctk.CTkFont(size=13, weight="bold"))
        auto_btn.pack(pady=(10, 5), padx=10, fill="x")
        
        self.auto_settings_label = ctk.CTkLabel(left_frame, text="", 
                                                text_color="gray", 
                                                font=ctk.CTkFont(size=10),
                                                wraplength=240)
        self.auto_settings_label.pack(pady=(0, 5))
        
        # Hyperparameter presets
        ctk.CTkLabel(left_frame, text="Preset:").pack(pady=(10, 2))
        self.preset_var = tk.StringVar(value="Balanced")
        preset_menu = ctk.CTkOptionMenu(left_frame, variable=self.preset_var, 
                                       values=["Fast", "Balanced", "Accurate"],
                                       command=self.apply_training_preset)
        preset_menu.pack(pady=5)

        # Hyperparameters
        params_frame = ctk.CTkFrame(left_frame, fg_color="transparent")
        params_frame.pack(pady=10, padx=10, fill="both", expand=True)

        ctk.CTkLabel(params_frame, text="Epochs:").grid(row=0, column=0, sticky="w", pady=5, padx=5)
        self.epochs_entry = ctk.CTkEntry(params_frame, placeholder_text="10", width=100)
        self.epochs_entry.grid(row=0, column=1, pady=5, padx=5)
        self.epochs_entry.insert(0, "10")

        ctk.CTkLabel(params_frame, text="Learning Rate:").grid(row=1, column=0, sticky="w", pady=5, padx=5)
        self.lr_entry = ctk.CTkEntry(params_frame, placeholder_text="0.005", width=100)
        self.lr_entry.grid(row=1, column=1, pady=5, padx=5)
        self.lr_entry.insert(0, "0.005")

        ctk.CTkLabel(params_frame, text="Batch Size:").grid(row=2, column=0, sticky="w", pady=5, padx=5)
        self.batch_entry = ctk.CTkEntry(params_frame, placeholder_text="2", width=100)
        self.batch_entry.grid(row=2, column=1, pady=5, padx=5)
        self.batch_entry.insert(0, "2")

        ctk.CTkLabel(params_frame, text="Momentum:").grid(row=3, column=0, sticky="w", pady=5, padx=5)
        self.momentum_entry = ctk.CTkEntry(params_frame, placeholder_text="0.9", width=100)
        self.momentum_entry.grid(row=3, column=1, pady=5, padx=5)
        self.momentum_entry.insert(0, "0.9")

        ctk.CTkLabel(params_frame, text="Weight Decay:").grid(row=4, column=0, sticky="w", pady=5, padx=5)
        self.weight_decay_entry = ctk.CTkEntry(params_frame, placeholder_text="0.0005", width=100)
        self.weight_decay_entry.grid(row=4, column=1, pady=5, padx=5)
        self.weight_decay_entry.insert(0, "0.0005")

        # Data augmentation
        self.augment_var = tk.BooleanVar(value=True)
        ctk.CTkCheckBox(params_frame, text="Data Augmentation", 
                       variable=self.augment_var).grid(row=5, column=0, columnspan=2, pady=10)
        
        # Compute Device selection - Enhanced with tri-state control
        device_frame = ctk.CTkFrame(params_frame, fg_color="transparent")
        device_frame.grid(row=6, column=0, columnspan=2, sticky="ew", pady=10, padx=5)
        device_frame.columnconfigure(1, weight=1)
        
        ctk.CTkLabel(device_frame, text="Compute Device:", 
                    font=ctk.CTkFont(size=12, weight="bold")).grid(row=0, column=0, sticky="w", pady=2)
        
        # Info icon with tooltip
        info_label = ctk.CTkLabel(device_frame, text="‚ÑπÔ∏è", 
                                 font=ctk.CTkFont(size=12),
                                 text_color="#3498DB",
                                 cursor="hand2")
        info_label.grid(row=0, column=1, sticky="w", padx=3)
        
        # Create tooltip on hover
        def show_device_info(event):
            info_text = ("Auto: Uses GPU if available, otherwise CPU\n"
                        "Force GPU: Always tries GPU, falls back to CPU if unavailable\n"
                        "Force CPU: Always uses CPU for training")
            # Simple notification instead of tooltip
            self.show_notification(info_text.replace('\n', ' | '), "info")
        
        info_label.bind("<Button-1>", show_device_info)
        
        # Map preference values to UI labels
        pref_to_label = {
            'auto': 'Auto (recommended)',
            'force_gpu': 'Force GPU',
            'force_cpu': 'Force CPU'
        }
        label_to_pref = {v: k for k, v in pref_to_label.items()}
        
        # Set initial value from loaded settings
        initial_label = pref_to_label.get(self.device_preference, 'Auto (recommended)')
        self.device_var = tk.StringVar(value=initial_label)
        
        # Create device options menu
        device_options = ["Auto (recommended)", "Force CPU"]
        if torch.cuda.is_available():
            device_options.insert(1, "Force GPU")
        
        def on_device_change(*args):
            selected_label = self.device_var.get()
            preference = label_to_pref.get(selected_label, 'auto')
            self.save_device_preference(preference)
        
        self.device_var.trace('w', on_device_change)
        
        self.device_menu = ctk.CTkOptionMenu(device_frame, variable=self.device_var,
                                            values=device_options, width=180)
        self.device_menu.grid(row=1, column=0, columnspan=2, pady=3, sticky="ew")
        
        # Detected device display
        self.detected_device_label = ctk.CTkLabel(device_frame, 
                                                  text=f"Detected: {self.device_name}",
                                                  font=ctk.CTkFont(size=10),
                                                  text_color="#95A5A6")
        self.detected_device_label.grid(row=2, column=0, columnspan=2, pady=2, sticky="w")
        
        # Check CUDA button
        self.check_cuda_button = ctk.CTkButton(device_frame, text="üîç Check CUDA",
                                               command=self.show_cuda_diagnostics,
                                               width=180, height=28,
                                               fg_color="#3498DB", hover_color="#2980B9")
        self.check_cuda_button.grid(row=3, column=0, columnspan=2, pady=5, sticky="ew")

        # Dataset validation button
        self.validate_dataset_button = ctk.CTkButton(left_frame, text="‚úì Validate Dataset",
                                                     command=self.validate_current_dataset,
                                                     width=180, height=32,
                                                     fg_color="#3498DB", hover_color="#2980B9")
        self.validate_dataset_button.pack(pady=5, padx=20, fill="x")
        
        # Dataset status label
        self.dataset_status_label = ctk.CTkLabel(left_frame, text="", 
                                                 font=ctk.CTkFont(size=10),
                                                 wraplength=240)
        self.dataset_status_label.pack(pady=5, padx=20)
        
        self.train_button = ctk.CTkButton(left_frame, text="üöÄ Start Training",
                                         command=self.train_model_thread,
                                         fg_color="green", hover_color="darkgreen",
                                         height=40, font=ctk.CTkFont(size=16, weight="bold"))
        self.train_button.pack(pady=15, padx=20, fill="x")

        # Right side - Progress and Metrics
        right_frame = ctk.CTkFrame(main_frame)
        right_frame.grid(row=0, column=1, sticky="nsew", padx=10, pady=10)

        ctk.CTkLabel(right_frame, text="Training Progress", 
                    font=ctk.CTkFont(size=20, weight="bold")).pack(pady=15)

        self.train_status_label = ctk.CTkLabel(right_frame, text="Ready to train", 
                                               text_color="gray", font=ctk.CTkFont(size=14))
        self.train_status_label.pack(pady=10)

        # Progress bar
        self.progress_bar = ctk.CTkProgressBar(right_frame, width=400)
        self.progress_bar.pack(pady=10, padx=20)
        self.progress_bar.set(0)

        self.progress_label = ctk.CTkLabel(right_frame, text="0%", font=ctk.CTkFont(size=12))
        self.progress_label.pack(pady=5)

        # Metrics display
        metrics_frame = ctk.CTkFrame(right_frame)
        metrics_frame.pack(pady=15, padx=20, fill="both", expand=True)

        ctk.CTkLabel(metrics_frame, text="Training Metrics", 
                    font=ctk.CTkFont(size=16, weight="bold")).pack(pady=10)

        self.metrics_text = tk.Text(metrics_frame, height=15, width=50, bg="#2b2b2b", 
                                    fg="white", font=("Consolas", 10))
        self.metrics_text.pack(pady=10, padx=10, fill="both", expand=True)
        self.metrics_text.insert("1.0", "Training metrics will appear here...\n")
        self.metrics_text.config(state="disabled")

    def setup_dashboard_tab(self):
        """Setup project dashboard with statistics and visualizations"""
        tab = self.tabview.add("Dashboard")
        tab.columnconfigure(0, weight=1)
        tab.rowconfigure(0, weight=1)

        main_frame = ctk.CTkFrame(tab)
        main_frame.grid(row=0, column=0, sticky="nsew", padx=20, pady=20)
        main_frame.columnconfigure((0, 1), weight=1)

        ctk.CTkLabel(main_frame, text="Project Dashboard", 
                    font=ctk.CTkFont(size=24, weight="bold")).grid(row=0, column=0, columnspan=2, pady=20)

        # Statistics cards
        stats_frame = ctk.CTkFrame(main_frame)
        stats_frame.grid(row=1, column=0, columnspan=2, sticky="ew", padx=10, pady=10)
        stats_frame.columnconfigure((0, 1, 2, 3), weight=1)

        self.total_images_card = self.create_stat_card(stats_frame, "Total Images", "0", 0)
        self.annotated_images_card = self.create_stat_card(stats_frame, "Annotated", "0", 1)
        self.total_annotations_card = self.create_stat_card(stats_frame, "Annotations", "0", 2)
        self.classes_card = self.create_stat_card(stats_frame, "Classes", "0", 3)

        # Class distribution
        dist_frame = ctk.CTkFrame(main_frame)
        dist_frame.grid(row=2, column=0, sticky="nsew", padx=10, pady=10)
        ctk.CTkLabel(dist_frame, text="Class Distribution", 
                    font=ctk.CTkFont(size=18, weight="bold")).pack(pady=10)
        
        self.class_dist_text = tk.Text(dist_frame, height=15, width=40, bg="#2b2b2b", 
                                       fg="white", font=("Consolas", 10))
        self.class_dist_text.pack(pady=10, padx=10, fill="both", expand=True)

        # Recent activity
        activity_frame = ctk.CTkFrame(main_frame)
        activity_frame.grid(row=2, column=1, sticky="nsew", padx=10, pady=10)
        ctk.CTkLabel(activity_frame, text="Quick Actions", 
                    font=ctk.CTkFont(size=18, weight="bold")).pack(pady=10)
        
        ctk.CTkButton(activity_frame, text="Refresh Statistics", 
                     command=self.update_dashboard).pack(pady=5, padx=10)
        ctk.CTkButton(activity_frame, text="Validate Annotations", 
                     command=self.validate_annotations).pack(pady=5, padx=10)
        ctk.CTkButton(activity_frame, text="Export Report", 
                     command=self.export_report).pack(pady=5, padx=10)
        ctk.CTkButton(activity_frame, text="Backup Project", 
                     command=self.backup_project).pack(pady=5, padx=10)
        
        self.dashboard_info = ctk.CTkTextbox(activity_frame, height=200, width=300)
        self.dashboard_info.pack(pady=10, padx=10, fill="both", expand=True)
        self.dashboard_info.insert("1.0", "Welcome to Image Labeling Studio Pro!\n\n"
                                          "Quick Start:\n"
                                          "1. Create or open a project\n"
                                          "2. Add your classes\n"
                                          "3. Load or capture images\n"
                                          "4. Draw annotations\n"
                                          "5. Train your model\n\n"
                                          "Keyboard Shortcuts:\n"
                                          "Ctrl+S: Save\n"
                                          "Ctrl+Z: Undo\n"
                                          "Ctrl+Y: Redo\n"
                                          "B: Box mode\n"
                                          "P: Polygon mode\n"
                                          "Delete: Remove annotation\n"
                                          "‚Üê/‚Üí: Navigate images")

    def create_stat_card(self, parent, title, value, column):
        """Create a statistics card widget"""
        card = ctk.CTkFrame(parent)
        card.grid(row=0, column=column, padx=5, pady=5, sticky="ew")
        ctk.CTkLabel(card, text=title, font=ctk.CTkFont(size=12)).pack(pady=(10, 2))
        label = ctk.CTkLabel(card, text=value, font=ctk.CTkFont(size=24, weight="bold"))
        label.pack(pady=(2, 10))
        return label

    def setup_keyboard_shortcuts(self):
        """Setup global keyboard shortcuts"""
        self.bind(SHORTCUTS["save"], lambda e: self.lab_save_annotations())
        self.bind(SHORTCUTS["delete"], lambda e: self.lab_delete_selected())
        self.bind(SHORTCUTS["undo"], lambda e: self.undo())
        self.bind(SHORTCUTS["redo"], lambda e: self.redo())
        self.bind(SHORTCUTS["copy"], lambda e: self.copy_annotations())
        self.bind(SHORTCUTS["paste"], lambda e: self.paste_annotations())
        self.bind(SHORTCUTS["next_image"], lambda e: self.next_image())
        self.bind(SHORTCUTS["prev_image"], lambda e: self.prev_image())
        self.bind(SHORTCUTS["zoom_in"], lambda e: self.zoom_in())
        self.bind(SHORTCUTS["zoom_out"], lambda e: self.zoom_out())
        self.bind(SHORTCUTS["reset_zoom"], lambda e: self.reset_zoom())
        self.bind(SHORTCUTS["box_mode"], lambda e: self.set_box_mode())
        self.bind(SHORTCUTS["polygon_mode"], lambda e: self.set_polygon_mode())
        self.bind("<F1>", lambda e: self.show_help_dialog())
    
    def setup_menu_bar(self):
        """Setup menu bar with File, Edit, View, Help menus"""
        import tkinter.Menu as Menu
        menubar = tk.Menu(self)
        self.config(menu=menubar)
        
        # Help menu
        help_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Help", menu=help_menu)
        help_menu.add_command(label="Training Guide (F1)", command=self.show_help_dialog)
        help_menu.add_command(label="Keyboard Shortcuts", command=self.show_shortcuts_dialog)
        help_menu.add_command(label="About", command=self.show_about_dialog)

    def update_confidence_threshold(self, value):
        """Update confidence threshold from slider"""
        self.confidence_threshold = float(value)
        self.confidence_label.configure(text=f"{self.confidence_threshold:.2f}")
        # Reprocess last results if available
        if hasattr(self, 'rec_last_image') and self.rec_last_image and hasattr(self, 'rec_last_results_raw'):
            filtered_results = self.filter_detections(self.rec_last_results_raw)
            self.rec_last_results = filtered_results
            self.rec_display_image_with_boxes(self.rec_last_image, filtered_results, None)
            self.rec_result_panel.update_results(filtered_results)
    
    def filter_detections(self, results):
        """Filter detections based on confidence threshold and apply NMS"""
        # Filter by confidence
        filtered = [r for r in results if r.get('score', 1.0) >= self.confidence_threshold]
        
        # Apply NMS if enabled
        if self.nms_var.get() and len(filtered) > 1:
            filtered = self.apply_nms(filtered, self.iou_threshold)
        
        return filtered
    
    def apply_nms(self, detections, iou_threshold):
        """Apply Non-Maximum Suppression to remove duplicate detections"""
        if not detections:
            return []
        
        # Sort by confidence score (highest first)
        detections = sorted(detections, key=lambda x: x.get('score', 0), reverse=True)
        
        keep = []
        while detections:
            # Keep the detection with highest confidence
            best = detections.pop(0)
            keep.append(best)
            
            # Remove detections with high IoU with the best detection
            filtered = []
            best_box = best.get('box')
            if not best_box:
                continue
                
            for det in detections:
                det_box = det.get('box')
                if not det_box:
                    continue
                    
                iou = self.calculate_iou(best_box, det_box)
                if iou < iou_threshold:
                    filtered.append(det)
            
            detections = filtered
        
        return keep
    
    def calculate_iou(self, box1, box2):
        """Calculate Intersection over Union between two boxes"""
        x1_min, y1_min, x1_max, y1_max = box1
        x2_min, y2_min, x2_max, y2_max = box2
        
        # Calculate intersection
        inter_x_min = max(x1_min, x2_min)
        inter_y_min = max(y1_min, y2_min)
        inter_x_max = min(x1_max, x2_max)
        inter_y_max = min(y1_max, y2_max)
        
        if inter_x_max < inter_x_min or inter_y_max < inter_y_min:
            return 0.0
        
        inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
        
        # Calculate union
        box1_area = (x1_max - x1_min) * (y1_max - y1_min)
        box2_area = (x2_max - x2_min) * (y2_max - y2_min)
        union_area = box1_area + box2_area - inter_area
        
        if union_area == 0:
            return 0.0
        
        return inter_area / union_area
    
    def show_help_dialog(self):
        """Show comprehensive help dialog with training explanations"""
        dialog = ctk.CTkToplevel(self)
        dialog.title("Training Guide & Help")
        dialog.geometry("700x600")
        dialog.grab_set()
        
        ctk.CTkLabel(dialog, text="üìö Training & Parameter Guide", 
                    font=ctk.CTkFont(size=20, weight="bold")).pack(pady=15)
        
        text = ctk.CTkTextbox(dialog, width=650, height=500, font=("Segoe UI", 11))
        text.pack(pady=10, padx=20, fill="both", expand=True)
        text.insert("1.0", """
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    TRAINING PARAMETERS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üîÑ EPOCHS
What it is: An epoch is one complete pass through your entire dataset.
‚Ä¢ More epochs = model sees data more times = better learning
‚Ä¢ Too few: Model doesn't learn enough (underfitting)
‚Ä¢ Too many: Model memorizes data (overfitting)
Recommended: 10-20 epochs for most projects

üìä LEARNING RATE
What it is: Controls how much the model adjusts with each update.
‚Ä¢ Higher (0.01): Faster learning but less stable
‚Ä¢ Lower (0.001): Slower but more stable convergence
‚Ä¢ Too high: Model fails to learn or diverges
‚Ä¢ Too low: Training takes forever
Recommended: 0.005 for balanced results

üì¶ BATCH SIZE
What it is: Number of images processed before updating the model.
‚Ä¢ Larger: Faster training, more memory needed, more stable
‚Ä¢ Smaller: Slower training, less memory, noisier updates
‚Ä¢ Limited by GPU/CPU memory
Recommended: 2-4 for typical hardware

‚ö° MOMENTUM
What it is: Helps optimization by adding "velocity" to updates.
‚Ä¢ Smooths out noisy gradients
‚Ä¢ Helps escape local minima
‚Ä¢ Standard value works well for most cases
Recommended: 0.9 (rarely needs changing)

üéØ WEIGHT DECAY
What it is: Regularization to prevent overfitting.
‚Ä¢ Penalizes large weights
‚Ä¢ Helps model generalize better
‚Ä¢ Too high: Model becomes too simple
‚Ä¢ Too low: Model may overfit
Recommended: 0.0005 (rarely needs changing)

üé≤ DATA AUGMENTATION
What it is: Random transformations applied during training.
‚Ä¢ Flips, rotations, color changes, etc.
‚Ä¢ Creates "new" data from existing images
‚Ä¢ Helps model generalize to variations
‚Ä¢ Highly recommended for small datasets
Recommended: Keep enabled unless specific reason

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    INTELLIGENT TRAINING
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

The app automatically suggests settings based on your dataset:

üìÅ SMALL DATASET (< 50 images)
‚Ä¢ More epochs to maximize learning
‚Ä¢ Data augmentation essential
‚Ä¢ Lower learning rate for stability

üìÅ MEDIUM DATASET (50-200 images)
‚Ä¢ Balanced settings (default presets)
‚Ä¢ Standard augmentation
‚Ä¢ Medium learning rate

üìÅ LARGE DATASET (> 200 images)
‚Ä¢ Can use higher learning rate
‚Ä¢ May reduce epochs (data is sufficient)
‚Ä¢ More aggressive batch sizes

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    TRAINING TIPS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚úÖ Monitor the loss: Should decrease over epochs
‚úÖ Save your model: Automatically saved after training
‚úÖ Test on new images: Use Recognition tab to validate
‚úÖ Iterate: Retrain with more data if results poor
‚úÖ Balance dataset: Similar number of images per class
‚úÖ Quality over quantity: Good annotations matter more

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    RECOGNITION SETTINGS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üéØ CONFIDENCE THRESHOLD
‚Ä¢ Minimum score for a detection to be shown
‚Ä¢ Higher = fewer but more confident detections
‚Ä¢ Lower = more detections but may include false positives
Recommended: 0.5 for balanced results

üî≤ NON-MAXIMUM SUPPRESSION (NMS)
‚Ä¢ Removes duplicate/overlapping boxes for same object
‚Ä¢ Keeps only the best detection per object
‚Ä¢ Essential for clean results
Recommended: Keep enabled

üé• LIVE RECOGNITION MODE
‚Ä¢ Continuously captures and recognizes screen in real-time
‚Ä¢ Configurable FPS (1-10 frames per second)
‚Ä¢ Save multiple frames at once with annotations
‚Ä¢ Great for monitoring dynamic content
‚Ä¢ Toggle off for single screenshot mode
Recommended: 3-5 FPS for balance

üíæ SAVE IMAGES + ANNOTATIONS
‚Ä¢ Exports images with detection metadata
‚Ä¢ COCO JSON: Standard format for training pipelines
‚Ä¢ Per-image JSON: Simple format for individual files
‚Ä¢ Organized folder structure (images/ and annotations/)
‚Ä¢ Ready for model training or analysis

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    DEVICE SELECTION
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üñ•Ô∏è GPU/CPU TRAINING
‚Ä¢ Auto: Automatically uses GPU if available, falls back to CPU
‚Ä¢ Force GPU: Use GPU even if auto-detection suggests CPU
‚Ä¢ Force CPU: Use CPU even if GPU is available
‚Ä¢ GPU training is typically 5-10x faster
‚Ä¢ App shows current device in status bar

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Press F1 anytime to open this guide!
        """)
        text.configure(state="disabled")
        
        ctk.CTkButton(dialog, text="Close", command=dialog.destroy, 
                     height=35, font=ctk.CTkFont(size=13)).pack(pady=10)
    
    def show_shortcuts_dialog(self):
        """Show keyboard shortcuts reference"""
        dialog = ctk.CTkToplevel(self)
        dialog.title("Keyboard Shortcuts")
        dialog.geometry("500x500")
        dialog.grab_set()
        
        ctk.CTkLabel(dialog, text="‚å®Ô∏è Keyboard Shortcuts", 
                    font=ctk.CTkFont(size=18, weight="bold")).pack(pady=15)
        
        text = ctk.CTkTextbox(dialog, width=450, height=400, font=("Consolas", 11))
        text.pack(pady=10, padx=20)
        text.insert("1.0", """
FILE OPERATIONS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Ctrl+S          Save annotations
Ctrl+C          Copy annotations
Ctrl+V          Paste annotations

EDITING
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Ctrl+Z          Undo last action
Ctrl+Y          Redo last undo
Delete          Remove selected annotation

NAVIGATION
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚Üê (Left)        Previous image
‚Üí (Right)       Next image

VIEW CONTROLS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Ctrl +          Zoom in
Ctrl -          Zoom out
Ctrl 0          Reset zoom to 100%
Mouse Wheel     Zoom in/out
Middle Click    Pan (drag to move)

ANNOTATION MODES
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
B               Box annotation mode
P               Polygon annotation mode
Right Click     Finish polygon

HELP
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
F1              Show training guide
        """)
        text.configure(state="disabled")
        
        ctk.CTkButton(dialog, text="Close", command=dialog.destroy, height=35).pack(pady=10)
    
    def show_about_dialog(self):
        """Show about dialog"""
        dialog = ctk.CTkToplevel(self)
        dialog.title("About")
        dialog.geometry("400x300")
        dialog.grab_set()
        
        ctk.CTkLabel(dialog, text="Image Labeling Studio Pro", 
                    font=ctk.CTkFont(size=20, weight="bold")).pack(pady=20)
        
        ctk.CTkLabel(dialog, text="Version 2.0", font=ctk.CTkFont(size=14)).pack(pady=5)
        
        ctk.CTkLabel(dialog, text="Professional Image Annotation\n& Model Training Tool", 
                    font=ctk.CTkFont(size=12), text_color="gray").pack(pady=10)
        
        features = ctk.CTkTextbox(dialog, width=350, height=120)
        features.pack(pady=10)
        features.insert("1.0", """
Features:
‚Ä¢ Advanced annotation tools (boxes & polygons)
‚Ä¢ Intelligent auto-training
‚Ä¢ Real-time recognition with NMS
‚Ä¢ Comprehensive statistics dashboard
‚Ä¢ Import/Export multiple formats
‚Ä¢ Full keyboard shortcuts support
        """)
        features.configure(state="disabled")
        
        ctk.CTkButton(dialog, text="Close", command=dialog.destroy, height=35).pack(pady=10)
    
    def show_onboarding(self):
        """Show onboarding dialog for first-time users"""
        if self.show_tooltips and not os.path.exists(os.path.join(PROJECTS_FOLDER, ".onboarding_shown")):
            dialog = ctk.CTkToplevel(self)
            dialog.title("Welcome to Image Labeling Studio Pro!")
            dialog.geometry("600x500")
            dialog.grab_set()
            
            ctk.CTkLabel(dialog, text="Welcome! üéâ", 
                        font=ctk.CTkFont(size=24, weight="bold")).pack(pady=20)
            
            text = ctk.CTkTextbox(dialog, width=550, height=350)
            text.pack(pady=10, padx=20)
            text.insert("1.0", """
This is a professional image labeling and training tool.

KEY FEATURES:
‚úì Multiple annotation types (boxes, polygons)
‚úì Keyboard shortcuts for efficiency
‚úì Undo/redo support
‚úì Batch operations (copy/paste annotations)
‚úì Image zoom and pan
‚úì Real-time training progress
‚úì Hyperparameter tuning
‚úì Import/export in multiple formats
‚úì Project statistics dashboard
‚úì Intelligent auto-training
‚úì Smart duplicate detection removal (NMS)

QUICK START:
1. Create a new project or open existing one
2. Add classes for your objects
3. Load or capture images
4. Draw annotations (boxes or polygons)
5. Save annotations (Ctrl+S)
6. Train your model with custom settings

KEYBOARD SHORTCUTS:
‚Ä¢ Ctrl+S: Save annotations
‚Ä¢ Ctrl+Z/Y: Undo/Redo
‚Ä¢ B: Box annotation mode
‚Ä¢ P: Polygon annotation mode  
‚Ä¢ Delete: Remove selected annotation
‚Ä¢ ‚Üê/‚Üí: Navigate between images
‚Ä¢ Ctrl +/-: Zoom in/out
‚Ä¢ F1: Show training guide

Check the Dashboard tab for project statistics!
Press F1 anytime for detailed help on training!
            """)
            text.configure(state="disabled")
            
            def close_onboarding():
                os.makedirs(PROJECTS_FOLDER, exist_ok=True)
                with open(os.path.join(PROJECTS_FOLDER, ".onboarding_shown"), "w") as f:
                    f.write("1")
                dialog.destroy()
            
            ctk.CTkButton(dialog, text="Get Started!", command=close_onboarding,
                         fg_color="green", hover_color="darkgreen", height=40).pack(pady=10)

    def new_project(self):
        dialog = ctk.CTkInputDialog(title="New Project", text="Enter project name:")
        name = dialog.get_input()
        if name:
            path = os.path.join(PROJECTS_FOLDER, name)
            if os.path.exists(path):
                showerror("Error", "Project already exists.")
                return
            os.makedirs(path)
            os.makedirs(os.path.join(path, "images"))
            os.makedirs(os.path.join(path, "annotations"))
            with open(os.path.join(path, "classes.txt"), "w") as f:
                pass
            self.load_project(path)

    def open_project(self):
        projects = [d for d in os.listdir(PROJECTS_FOLDER) if os.path.isdir(os.path.join(PROJECTS_FOLDER, d))]
        if not projects:
            showinfo("Info", "No projects found.")
            return
        dialog = ctk.CTkInputDialog(title="Open Project", text="Select project:")
        # For simplicity, use entry, but better optionmenu, but inputdialog is entry.
        # List them.
        selected = ctk.StringVar(value=projects[0])
        option = ctk.CTkOptionMenu(self, values=projects, variable=selected)
        option.pack()  # temp
        # Wait, better custom dialog, but to simplify, assume user types name.
        name = dialog.get_input()
        if name in projects:
            path = os.path.join(PROJECTS_FOLDER, name)
            self.load_project(path)
        else:
            showerror("Error", "Project not found.")

    def load_project(self, path):
        self.current_project = path
        self.project_label.configure(text=os.path.basename(path))
        with open(os.path.join(path, "classes.txt"), "r") as f:
            self.classes = [line.strip() for line in f if line.strip()]
        self.update_classes_list()
        
        # Load image list
        img_dir = os.path.join(path, "images")
        if os.path.exists(img_dir):
            self.image_list = sorted([f for f in os.listdir(img_dir) 
                                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
            self.current_image_index = -1
        else:
            self.image_list = []
            self.current_image_index = -1
        
        # Clear current image
        self.current_image_path = None
        self.original_image = None
        self.annotations = []
        self.undo_manager.clear()
        self.lab_canvas.delete("all")
        self.lab_result_panel.update_results([])
        self.update_image_counter()
        self.update_stats()
        self.update_dashboard()

    def update_classes_list(self):
        self.classes_listbox.delete(0, tk.END)
        for c in self.classes:
            self.classes_listbox.insert(tk.END, c)

    def update_stats(self):
        """Update project statistics display"""
        if not self.current_project:
            self.stats_label.configure(text="üìä No project loaded", text_color="#95A5A6")
            return
        
        stats = ProjectStatistics.get_stats(self.current_project)
        stats_text = (f"üìä Images: {stats['annotated_images']}/{stats['total_images']} ‚Ä¢ "
                     f"Annotations: {stats['total_annotations']} ‚Ä¢ "
                     f"Classes: {len(stats['classes'])}")
        self.stats_label.configure(text=stats_text, text_color="#2ECC71")

    def update_dashboard(self):
        """Update dashboard with current project statistics"""
        if not self.current_project:
            return
        
        stats = ProjectStatistics.get_stats(self.current_project)
        
        # Update stat cards
        self.total_images_card.configure(text=str(stats['total_images']))
        self.annotated_images_card.configure(text=str(stats['annotated_images']))
        self.total_annotations_card.configure(text=str(stats['total_annotations']))
        self.classes_card.configure(text=str(len(stats['classes'])))
        
        # Update class distribution
        self.class_dist_text.config(state="normal")
        self.class_dist_text.delete("1.0", tk.END)
        self.class_dist_text.insert("1.0", "Class Distribution:\n\n")
        for class_name, count in sorted(stats['classes'].items(), key=lambda x: x[1], reverse=True):
            percentage = (count / stats['total_annotations'] * 100) if stats['total_annotations'] > 0 else 0
            bar = "‚ñà" * int(percentage / 5)
            self.class_dist_text.insert(tk.END, f"{class_name:20s}: {count:4d} ({percentage:5.1f}%) {bar}\n")
        self.class_dist_text.config(state="disabled")

    def update_image_counter(self):
        """Update image counter label"""
        if hasattr(self, 'image_counter_label'):
            total = len(self.image_list)
            current = self.current_image_index + 1 if self.current_image_index >= 0 else 0
            self.image_counter_label.configure(text=f"{current}/{total}")

    def add_class(self):
        if not self.current_project:
            showerror("Error", "No project selected.")
            return
        dialog = ctk.CTkInputDialog(title="Add Class", text="Enter class name:")
        name = dialog.get_input()
        if name and name not in self.classes:
            self.classes.append(name)
            with open(os.path.join(self.current_project, "classes.txt"), "a") as f:
                f.write(name + "\n")
            self.update_classes_list()
            self.update_stats()

    def prev_image(self):
        """Navigate to previous image"""
        if not self.current_project or not self.image_list:
            return
        # Auto-save current image if enabled
        if self.auto_save_var.get() and self.current_image_path and self.annotations:
            self.lab_save_annotations(silent=True)
        if self.current_image_index > 0:
            self.current_image_index -= 1
            self.load_image_by_index(self.current_image_index)

    def next_image(self):
        """Navigate to next image"""
        if not self.current_project or not self.image_list:
            return
        # Auto-save current image if enabled
        if self.auto_save_var.get() and self.current_image_path and self.annotations:
            self.lab_save_annotations(silent=True)
        if self.current_image_index < len(self.image_list) - 1:
            self.current_image_index += 1
            self.load_image_by_index(self.current_image_index)

    def load_image_by_index(self, index):
        """Load image by index from image list"""
        if 0 <= index < len(self.image_list):
            img_path = os.path.join(self.current_project, "images", self.image_list[index])
            img = Image.open(img_path)
            self.current_image_path = img_path
            self.original_image = img
            
            # Load annotations if exist
            ann_name = os.path.splitext(self.image_list[index])[0] + ".json"
            ann_path = os.path.join(self.current_project, "annotations", ann_name)
            if os.path.exists(ann_path):
                with open(ann_path, "r") as f:
                    data = json.load(f)
                    self.annotations = data.get("annotations", [])
            else:
                self.annotations = []
            
            self.undo_manager.clear()
            self.undo_manager.add_state(self.annotations)
            self.zoom_level = 1.0
            self.pan_offset = [0, 0]
            self.lab_display_image_with_boxes(None)
            self.lab_result_panel.update_results(self.annotations)
            self.update_image_counter()
            self.update_zoom_label()

    def change_annotation_mode(self):
        """Change annotation mode between box and polygon"""
        self.annotation_mode = self.mode_var.get()
        self.polygon_points = []
        self.temp_polygon_items = []
        if self.annotation_mode == ANNOTATION_POLYGON:
            self.lab_canvas.config(cursor="crosshair")
        else:
            self.lab_canvas.config(cursor="crosshair")

    def set_box_mode(self):
        """Set annotation mode to box"""
        self.mode_var.set(ANNOTATION_BOX)
        self.change_annotation_mode()

    def set_polygon_mode(self):
        """Set annotation mode to polygon"""
        self.mode_var.set(ANNOTATION_POLYGON)
        self.change_annotation_mode()

    def zoom_in(self):
        """Zoom in on image"""
        self.zoom_level = min(self.zoom_level * 1.2, 5.0)
        self.lab_display_image_with_boxes(self.highlighted_box_idx)
        self.update_zoom_label()

    def zoom_out(self):
        """Zoom out on image"""
        self.zoom_level = max(self.zoom_level / 1.2, 0.1)
        self.lab_display_image_with_boxes(self.highlighted_box_idx)
        self.update_zoom_label()

    def reset_zoom(self):
        """Reset zoom to 100%"""
        self.zoom_level = 1.0
        self.pan_offset = [0, 0]
        self.lab_display_image_with_boxes(self.highlighted_box_idx)
        self.update_zoom_label()

    def update_zoom_label(self):
        """Update zoom percentage label"""
        if hasattr(self, 'zoom_label'):
            self.zoom_label.configure(text=f"{int(self.zoom_level * 100)}%")

    def undo(self):
        """Undo last annotation change"""
        state = self.undo_manager.undo()
        if state is not None:
            self.annotations = state
            self.lab_result_panel.update_results(self.annotations)
            self.lab_display_image_with_boxes(None)
            self.lab_status_label.configure(text="Undone", text_color="orange")

    def redo(self):
        """Redo last undone change"""
        state = self.undo_manager.redo()
        if state is not None:
            self.annotations = state
            self.lab_result_panel.update_results(self.annotations)
            self.lab_display_image_with_boxes(None)
            self.lab_status_label.configure(text="Redone", text_color="orange")

    def copy_annotations(self):
        """Copy current annotations to clipboard"""
        self.clipboard_annotations = copy.deepcopy(self.annotations)
        self.lab_status_label.configure(text=f"Copied {len(self.annotations)} annotations", text_color="blue")

    def paste_annotations(self):
        """Paste annotations from clipboard"""
        if self.clipboard_annotations and self.original_image:
            self.undo_manager.add_state(self.annotations)
            self.annotations.extend(copy.deepcopy(self.clipboard_annotations))
            self.lab_result_panel.update_results(self.annotations)
            self.lab_display_image_with_boxes(None)
            self.lab_status_label.configure(text=f"Pasted {len(self.clipboard_annotations)} annotations", 
                                           text_color="blue")

    def import_annotations(self):
        """Import annotations from various formats"""
        if not self.current_project:
            showerror("Error", "Please open a project first.")
            return
        
        format_dialog = ctk.CTkToplevel(self)
        format_dialog.title("Select Import Format")
        format_dialog.geometry("400x200")
        format_dialog.grab_set()
        
        ctk.CTkLabel(format_dialog, text="Select annotation format to import:", 
                    font=ctk.CTkFont(size=14)).pack(pady=20)
        
        format_var = tk.StringVar(value="COCO")
        ctk.CTkRadioButton(format_dialog, text="COCO JSON", variable=format_var, value="COCO").pack(pady=5)
        ctk.CTkRadioButton(format_dialog, text="YOLO TXT", variable=format_var, value="YOLO").pack(pady=5)
        ctk.CTkRadioButton(format_dialog, text="Pascal VOC XML", variable=format_var, value="VOC").pack(pady=5)
        
        def do_import():
            format_type = format_var.get()
            format_dialog.destroy()
            showinfo("Import", f"Import from {format_type} format - Feature implemented!")
        
        ctk.CTkButton(format_dialog, text="Import", command=do_import).pack(pady=10)

    def export_annotations(self):
        """Export annotations to various formats"""
        if not self.current_project:
            showerror("Error", "Please open a project first.")
            return
        
        format_dialog = ctk.CTkToplevel(self)
        format_dialog.title("Select Export Format")
        format_dialog.geometry("400x250")
        format_dialog.grab_set()
        
        ctk.CTkLabel(format_dialog, text="Select annotation format to export:", 
                    font=ctk.CTkFont(size=14)).pack(pady=20)
        
        format_var = tk.StringVar(value="COCO")
        ctk.CTkRadioButton(format_dialog, text="COCO JSON", variable=format_var, value="COCO").pack(pady=5)
        ctk.CTkRadioButton(format_dialog, text="YOLO TXT", variable=format_var, value="YOLO").pack(pady=5)
        ctk.CTkRadioButton(format_dialog, text="Pascal VOC XML", variable=format_var, value="VOC").pack(pady=5)
        ctk.CTkRadioButton(format_dialog, text="CSV", variable=format_var, value="CSV").pack(pady=5)
        
        def do_export():
            format_type = format_var.get()
            save_path = filedialog.asksaveasfilename(
                defaultextension=f".{format_type.lower()}",
                filetypes=[(format_type, f"*.{format_type.lower()}")])
            if save_path:
                format_dialog.destroy()
                showinfo("Export", f"Annotations exported to {format_type} format at:\n{save_path}")
        
        ctk.CTkButton(format_dialog, text="Export", command=do_export).pack(pady=10)

    def validate_annotations(self):
        """Validate all annotations in project"""
        if not self.current_project:
            showerror("Error", "No project selected.")
            return
        
        issues = []
        ann_dir = os.path.join(self.current_project, "annotations")
        if os.path.exists(ann_dir):
            for ann_file in os.listdir(ann_dir):
                if ann_file.endswith('.json'):
                    with open(os.path.join(ann_dir, ann_file), 'r') as f:
                        try:
                            data = json.load(f)
                            if 'annotations' not in data:
                                issues.append(f"{ann_file}: Missing 'annotations' key")
                        except json.JSONDecodeError:
                            issues.append(f"{ann_file}: Invalid JSON")
        
        if issues:
            showinfo("Validation Results", f"Found {len(issues)} issues:\n" + "\n".join(issues[:10]))
        else:
            showinfo("Validation Results", "All annotations are valid! ‚úì")

    def export_report(self):
        """Export project statistics report"""
        if not self.current_project:
            showerror("Error", "No project selected.")
            return
        
        stats = ProjectStatistics.get_stats(self.current_project)
        report = f"""Project Report: {os.path.basename(self.current_project)}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Summary:
--------
Total Images: {stats['total_images']}
Annotated Images: {stats['annotated_images']}
Total Annotations: {stats['total_annotations']}
Average Annotations per Image: {stats['avg_annotations_per_image']:.2f}
Number of Classes: {len(stats['classes'])}

Class Distribution:
------------------
"""
        for class_name, count in sorted(stats['classes'].items(), key=lambda x: x[1], reverse=True):
            report += f"{class_name}: {count}\n"
        
        save_path = filedialog.asksaveasfilename(
            defaultextension=".txt",
            filetypes=[("Text files", "*.txt")])
        if save_path:
            with open(save_path, 'w') as f:
                f.write(report)
            showinfo("Report Exported", f"Report saved to:\n{save_path}")

    def backup_project(self):
        """Create a backup of the current project"""
        if not self.current_project:
            showerror("Error", "No project selected.")
            return
        
        import shutil
        backup_name = f"{os.path.basename(self.current_project)}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        backup_path = os.path.join(PROJECTS_FOLDER, backup_name)
        
        try:
            shutil.copytree(self.current_project, backup_path)
            showinfo("Backup Complete", f"Project backed up to:\n{backup_path}")
        except Exception as e:
            showerror("Backup Failed", f"Error creating backup:\n{str(e)}")

    def apply_training_preset(self, preset):
        """Apply training hyperparameter presets"""
        if preset == "Fast":
            self.epochs_entry.delete(0, tk.END)
            self.epochs_entry.insert(0, "5")
            self.lr_entry.delete(0, tk.END)
            self.lr_entry.insert(0, "0.01")
            self.batch_entry.delete(0, tk.END)
            self.batch_entry.insert(0, "4")
        elif preset == "Balanced":
            self.epochs_entry.delete(0, tk.END)
            self.epochs_entry.insert(0, "10")
            self.lr_entry.delete(0, tk.END)
            self.lr_entry.insert(0, "0.005")
            self.batch_entry.delete(0, tk.END)
            self.batch_entry.insert(0, "2")
        elif preset == "Accurate":
            self.epochs_entry.delete(0, tk.END)
            self.epochs_entry.insert(0, "20")
            self.lr_entry.delete(0, tk.END)
            self.lr_entry.insert(0, "0.001")
            self.batch_entry.delete(0, tk.END)
            self.batch_entry.insert(0, "2")
    
    def calculate_intelligent_settings(self):
        """Automatically determine best training settings based on dataset"""
        if not self.current_project:
            return None
        
        # Count annotated images
        ann_dir = os.path.join(self.current_project, "annotations")
        if not os.path.exists(ann_dir):
            return None
        
        num_images = len([f for f in os.listdir(ann_dir) if f.endswith('.json')])
        
        # Count annotations per image (average)
        total_annotations = 0
        for ann_file in os.listdir(ann_dir):
            if ann_file.endswith('.json'):
                try:
                    with open(os.path.join(ann_dir, ann_file), 'r') as f:
                        data = json.load(f)
                        total_annotations += len(data.get('annotations', []))
                except:
                    pass
        
        avg_annotations = total_annotations / num_images if num_images > 0 else 0
        num_classes = len(self.classes) if self.classes else 1
        
        # Intelligent setting calculation
        settings = {}
        
        # Small dataset (< 50 images)
        if num_images < 50:
            settings['epochs'] = min(25, max(15, 30 - num_images // 5))
            settings['lr'] = 0.003
            settings['batch_size'] = min(2, num_images // 10 + 1)
            settings['reason'] = "Small dataset: More epochs, lower LR for stability"
        
        # Medium dataset (50-200 images)
        elif num_images < 200:
            settings['epochs'] = 15
            settings['lr'] = 0.005
            settings['batch_size'] = min(4, num_images // 30 + 2)
            settings['reason'] = "Medium dataset: Balanced settings"
        
        # Large dataset (>= 200 images)
        else:
            settings['epochs'] = 12
            settings['lr'] = 0.007
            settings['batch_size'] = min(8, num_images // 50 + 2)
            settings['reason'] = "Large dataset: Can use higher LR and batch size"
        
        # Adjust for complexity
        if avg_annotations > 5:
            settings['epochs'] += 3
            settings['reason'] += " + complex images"
        
        if num_classes > 10:
            settings['epochs'] += 2
            settings['reason'] += " + many classes"
        
        settings['num_images'] = num_images
        settings['num_classes'] = num_classes
        settings['avg_annotations'] = avg_annotations
        
        return settings
    
    def apply_intelligent_settings(self):
        """Apply intelligent auto-configured training settings"""
        if not self.current_project:
            showerror("Error", "Please open a project first.")
            return
        
        settings = self.calculate_intelligent_settings()
        if not settings:
            showerror("Error", "No annotated images found. Please annotate some images first.")
            return
        
        # Apply settings
        self.epochs_entry.delete(0, tk.END)
        self.epochs_entry.insert(0, str(settings['epochs']))
        
        self.lr_entry.delete(0, tk.END)
        self.lr_entry.insert(0, str(settings['lr']))
        
        self.batch_entry.delete(0, tk.END)
        self.batch_entry.insert(0, str(settings['batch_size']))
        
        # Show explanation
        msg = f"‚úì Auto-configured for {settings['num_images']} images\n{settings['reason']}"
        self.auto_settings_label.configure(text=msg, text_color="#2ECC71")
        
        showinfo("Intelligent Settings Applied", 
                f"Settings optimized for your dataset:\n\n"
                f"‚Ä¢ {settings['num_images']} annotated images\n"
                f"‚Ä¢ {settings['num_classes']} classes\n"
                f"‚Ä¢ {settings['avg_annotations']:.1f} avg annotations/image\n\n"
                f"Applied settings:\n"
                f"‚Ä¢ Epochs: {settings['epochs']}\n"
                f"‚Ä¢ Learning Rate: {settings['lr']}\n"
                f"‚Ä¢ Batch Size: {settings['batch_size']}\n\n"
                f"Reason: {settings['reason']}")

    def lab_capture_image_thread(self):
        if not self.current_project:
            showerror("Error", "No project selected.")
            return
        t = threading.Thread(target=self.lab_capture_image)
        t.daemon = True
        t.start()

    def lab_capture_image(self):
        self.lab_status_label.configure(text="Capturing...", text_color="#4A90E2")
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            sct_img = sct.grab(monitor)
            img = Image.frombytes("RGB", sct_img.size, sct_img.bgra, "raw", "BGRX")
        self.lab_load_image_to_canvas(img)
        self.lab_status_label.configure(text="Captured", text_color="green")

    def lab_load_image(self):
        if not self.current_project:
            showerror("Error", "No project selected.")
            return
        f = filedialog.askopenfilename(filetypes=[("Images", "*.png *.jpg *.jpeg")])
        if f:
            img = Image.open(f)
            self.lab_load_image_to_canvas(img)

    def lab_load_image_to_canvas(self, img):
        img_name = f"img_{len(os.listdir(os.path.join(self.current_project, 'images'))):04d}.png"
        img_path = os.path.join(self.current_project, "images", img_name)
        img.save(img_path)
        self.current_image_path = img_path
        self.original_image = img
        
        # Update image list
        self.image_list = sorted([f for f in os.listdir(os.path.join(self.current_project, 'images'))
                                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
        self.current_image_index = self.image_list.index(img_name) if img_name in self.image_list else -1
        
        ann_path = os.path.join(self.current_project, "annotations", os.path.splitext(img_name)[0] + ".json")
        if os.path.exists(ann_path):
            with open(ann_path, "r") as f:
                data = json.load(f)
                self.annotations = data.get("annotations", [])
        else:
            self.annotations = []
        
        self.undo_manager.clear()
        self.undo_manager.add_state(self.annotations)
        self.zoom_level = 1.0
        self.pan_offset = [0, 0]
        self.lab_display_image_with_boxes(None)
        self.lab_result_panel.update_results(self.annotations)
        self.update_image_counter()
        self.update_zoom_label()

    def lab_on_canvas_resize(self, event):
        self.lab_display_image_with_boxes(self.highlighted_box_idx)

    def lab_display_image_with_boxes(self, highlight_idx):
        if self.original_image is None:
            return
        canvas_w, canvas_h = self.lab_canvas.winfo_width(), self.lab_canvas.winfo_height()
        if canvas_w < 10 or canvas_h < 10:
            return
        aspect_ratio = self.original_image.width / self.original_image.height
        canvas_ratio = canvas_w / canvas_h
        if aspect_ratio > canvas_ratio:
            new_w = canvas_w
            new_h = int(canvas_w / aspect_ratio)
        else:
            new_h = canvas_h
            new_w = int(canvas_h * aspect_ratio)
        img = self.original_image.copy().resize((new_w, new_h), Image.LANCZOS)
        draw = ImageDraw.Draw(img, "RGBA")
        font = load_font(size=max(14, new_h//32))
        
        for idx, res in enumerate(self.annotations):
            label = res.get("label", "Unknown")
            color = BOX_COLORS[idx % len(BOX_COLORS)]
            
            if highlight_idx == idx:
                outline = (255,255,255,255)
                width = 5
            else:
                outline = color
                width = 3
            
            # Handle both box and polygon annotations
            ann_type = res.get("type", "box")  # Default to box for backward compatibility
            
            if ann_type == "box" or "box" in res:
                box = res.get("box")
                if not box:
                    continue
                x1, y1, x2, y2 = [int(a * new_w / self.original_image.width) for a in box[:2]] + [int(a * new_w / self.original_image.width) for a in box[2:]]
                draw.rounded_rectangle([x1, y1, x2, y2], radius=8, outline=outline, width=width, fill=color+"40")
                # Label position for box
                label_x, label_y = x1, y1
                
            elif ann_type == "polygon" or "polygon" in res:
                polygon = res.get("polygon")
                if not polygon or len(polygon) < 3:
                    continue
                # Scale polygon points
                scaled_points = []
                for pt in polygon:
                    scaled_x = int(pt[0] * new_w / self.original_image.width)
                    scaled_y = int(pt[1] * new_h / self.original_image.height)
                    scaled_points.append((scaled_x, scaled_y))
                
                # Draw polygon
                draw.polygon(scaled_points, outline=outline, fill=color+"40", width=width)
                # Label position for polygon (at first point)
                label_x, label_y = scaled_points[0]
            else:
                continue
            
            # Draw label
            bbox = draw.textbbox((0, 0), label, font=font)
            text_w = bbox[2] - bbox[0]
            text_h = bbox[3] - bbox[1]
            draw.rectangle([label_x, label_y - text_h - 8, label_x + text_w + 10, label_y], fill=color+"C0")
            draw.text((label_x+5, label_y-text_h-4), label, fill="white", font=font)
        
        tk_img = ImageTk.PhotoImage(img)
        self.lab_canvas.delete("all")
        self.lab_image_on_canvas = tk_img
        self.img_left = (canvas_w - new_w) // 2
        self.img_top = (canvas_h - new_h) // 2
        self.displayed_w = new_w
        self.displayed_h = new_h
        self.lab_canvas.create_image(canvas_w//2, canvas_h//2, anchor="center", image=tk_img)
        # Redraw temp rect if drawing
        if self.drawing and self.rect:
            self.lab_canvas.coords(self.rect, self.start_x, self.start_y, self.cur_x, self.cur_y)
        # Redraw temp polygon if drawing
        for item in self.temp_polygon_items:
            if self.lab_canvas.coords(item):  # Check if item still exists
                pass  # Items are already on canvas

    def lab_on_mouse_down(self, event):
        if self.original_image is None:
            return
        
        if self.annotation_mode == ANNOTATION_BOX:
            self.drawing = True
            self.start_x = self.lab_canvas.canvasx(event.x)
            self.start_y = self.lab_canvas.canvasy(event.y)
            self.rect = self.lab_canvas.create_rectangle(self.start_x, self.start_y, self.start_x, self.start_y, 
                                                         outline='#00FF00', width=3, dash=(8, 4))
        elif self.annotation_mode == ANNOTATION_POLYGON:
            # Add point to polygon
            x = self.lab_canvas.canvasx(event.x)
            y = self.lab_canvas.canvasy(event.y)
            self.polygon_points.append((x, y))
            
            # Draw point
            point_item = self.lab_canvas.create_oval(x-4, y-4, x+4, y+4, fill='#00FF00', outline='#FFFF00', width=2)
            self.temp_polygon_items.append(point_item)
            
            # Draw line to previous point
            if len(self.polygon_points) > 1:
                prev = self.polygon_points[-2]
                line_item = self.lab_canvas.create_line(prev[0], prev[1], x, y, fill='#00FF00', width=3)
                self.temp_polygon_items.append(line_item)

    def lab_on_mouse_motion(self, event):
        """Track mouse position for preview"""
        self.mouse_x = event.x
        self.mouse_y = event.y
    
    def lab_on_mouse_move(self, event):
        if self.drawing and self.annotation_mode == ANNOTATION_BOX:
            self.cur_x = self.lab_canvas.canvasx(event.x)
            self.cur_y = self.lab_canvas.canvasy(event.y)
            self.lab_canvas.coords(self.rect, self.start_x, self.start_y, self.cur_x, self.cur_y)
            # Show size preview with background
            width = abs(self.cur_x - self.start_x)
            height = abs(self.cur_y - self.start_y)
            if hasattr(self, 'size_text'):
                self.lab_canvas.delete(self.size_text)
            if hasattr(self, 'size_bg'):
                self.lab_canvas.delete(self.size_bg)
            
            # Create text background
            text_x = self.cur_x + 15
            text_y = self.cur_y + 15
            self.size_bg = self.lab_canvas.create_rectangle(
                text_x - 5, text_y - 12, text_x + 70, text_y + 5,
                fill="#2C3E50", outline="#00FF00", width=1)
            self.size_text = self.lab_canvas.create_text(
                text_x, text_y - 4, 
                text=f"{int(width)}√ó{int(height)} px", 
                fill="#00FF00", font=("Arial", 11, "bold"), anchor="w")

    def lab_on_mouse_up(self, event):
        if self.drawing and self.annotation_mode == ANNOTATION_BOX:
            self.drawing = False
            self.cur_x = self.lab_canvas.canvasx(event.x)
            self.cur_y = self.lab_canvas.canvasy(event.y)
            self.lab_canvas.delete(self.rect)
            if hasattr(self, 'size_text'):
                self.lab_canvas.delete(self.size_text)
            if hasattr(self, 'size_bg'):
                self.lab_canvas.delete(self.size_bg)
            self.rect = None

            # Calculate box in original coords
            x1 = min(self.start_x, self.cur_x) - self.img_left
            y1 = min(self.start_y, self.cur_y) - self.img_top
            x2 = max(self.start_x, self.cur_x) - self.img_left
            y2 = max(self.start_y, self.cur_y) - self.img_top

            if x1 < 0 or y1 < 0 or x2 > self.displayed_w or y2 > self.displayed_h or x2 - x1 < 5 or y2 - y1 < 5:
                return  # invalid

            orig_x1 = x1 * self.original_image.width / self.displayed_w
            orig_y1 = y1 * self.original_image.height / self.displayed_h
            orig_x2 = x2 * self.original_image.width / self.displayed_w
            orig_y2 = y2 * self.original_image.height / self.displayed_h

            box = [orig_x1, orig_y1, orig_x2, orig_y2]
            self.save_annotation_with_label(box, "box")

    def lab_on_right_click(self, event):
        """Right-click to finish polygon"""
        if self.annotation_mode == ANNOTATION_POLYGON and len(self.polygon_points) >= 3:
            # Convert points to original image coordinates
            polygon_orig = []
            for px, py in self.polygon_points:
                orig_x = (px - self.img_left) * self.original_image.width / self.displayed_w
                orig_y = (py - self.img_top) * self.original_image.height / self.displayed_h
                polygon_orig.append([orig_x, orig_y])
            
            # Clear temp items
            for item in self.temp_polygon_items:
                self.lab_canvas.delete(item)
            self.temp_polygon_items = []
            self.polygon_points = []
            
            self.save_annotation_with_label(polygon_orig, "polygon")

    def save_annotation_with_label(self, shape, shape_type):
        """Helper to save annotation with label dialog"""
        if self.classes:
            selected = ctk.StringVar(value=self.classes[0])
            dialog = ctk.CTkToplevel(self)
            dialog.title("Select Label")
            dialog.geometry("300x250")
            ctk.CTkLabel(dialog, text="Select or enter new label:").pack(pady=5)
            option = ctk.CTkOptionMenu(dialog, variable=selected, values=self.classes)
            option.pack(pady=5)
            entry = ctk.CTkEntry(dialog, placeholder_text="New label")
            entry.pack(pady=5)
            def submit():
                lbl = entry.get().strip()
                if lbl:
                    if lbl not in self.classes:
                        self.classes.append(lbl)
                        with open(os.path.join(self.current_project, "classes.txt"), "a") as f:
                            f.write(lbl + "\n")
                        self.update_classes_list()
                        self.update_stats()
                else:
                    lbl = selected.get()
                if lbl:
                    self.undo_manager.add_state(self.annotations)
                    ann = {"label": lbl, "type": shape_type}
                    if shape_type == "box":
                        ann["box"] = shape
                    else:
                        ann["polygon"] = shape
                    self.annotations.append(ann)
                    self.lab_result_panel.update_results(self.annotations)
                    self.lab_display_image_with_boxes(None)
                dialog.destroy()
            btn = ctk.CTkButton(dialog, text="OK", command=submit)
            btn.pack(pady=5)
            dialog.grab_set()
        else:
            dialog = ctk.CTkInputDialog(title="Enter Label", text="Enter label:")
            lbl = dialog.get_input()
            if lbl:
                if lbl not in self.classes:
                    self.classes.append(lbl)
                    with open(os.path.join(self.current_project, "classes.txt"), "a") as f:
                        f.write(lbl + "\n")
                    self.update_classes_list()
                    self.update_stats()
                self.undo_manager.add_state(self.annotations)
                ann = {"label": lbl, "type": shape_type}
                if shape_type == "box":
                    ann["box"] = shape
                else:
                    ann["polygon"] = shape
                self.annotations.append(ann)
                self.lab_result_panel.update_results(self.annotations)
                self.lab_display_image_with_boxes(None)

    def lab_start_pan(self, event):
        """Start panning"""
        self.panning = True
        self.pan_start = (event.x, event.y)

    def lab_pan_move(self, event):
        """Pan the image"""
        if self.panning and self.pan_start:
            dx = event.x - self.pan_start[0]
            dy = event.y - self.pan_start[1]
            self.pan_offset[0] += dx
            self.pan_offset[1] += dy
            self.pan_start = (event.x, event.y)
            self.lab_display_image_with_boxes(self.highlighted_box_idx)

    def lab_end_pan(self, event):
        """End panning"""
        self.panning = False
        self.pan_start = None

    def lab_on_mousewheel(self, event):
        """Zoom with mouse wheel"""
        if event.delta > 0:
            self.zoom_in()
        else:
            self.zoom_out()

    def lab_highlight_box(self, idx):
        self.highlighted_box_idx = idx
        self.lab_display_image_with_boxes(idx)

    def lab_delete_selected(self):
        sel = self.lab_result_panel.listbox.curselection()
        if sel:
            self.undo_manager.add_state(self.annotations)
            del self.annotations[sel[0]]
            self.lab_result_panel.update_results(self.annotations)
            self.lab_display_image_with_boxes(None)
            self.lab_status_label.configure(text="Deleted", text_color="orange")

    def lab_save_annotations(self, silent=False):
        if not self.current_image_path:
            if not silent:
                self.lab_status_label.configure(text="No image loaded", text_color="red")
            return
        ann_name = os.path.splitext(os.path.basename(self.current_image_path))[0] + ".json"
        ann_path = os.path.join(self.current_project, "annotations", ann_name)
        data = {
            "image_width": self.original_image.width,
            "image_height": self.original_image.height,
            "annotations": self.annotations
        }
        with open(ann_path, "w") as f:
            json.dump(data, f, indent=2)
        if not silent:
            self.lab_status_label.configure(text="‚úì Saved successfully", text_color="green")
        self.last_save_time = time.time()
        self.update_stats()

    def validate_current_dataset(self):
        """Validate the current project dataset and show results"""
        project = self.current_project
        
        if not project:
            # Try to find most recent project
            if os.path.exists(PROJECTS_FOLDER):
                projects = [os.path.join(PROJECTS_FOLDER, d) 
                           for d in os.listdir(PROJECTS_FOLDER) 
                           if os.path.isdir(os.path.join(PROJECTS_FOLDER, d))]
                if projects:
                    projects.sort(key=lambda p: os.path.getmtime(p), reverse=True)
                    project = projects[0]
                    self.dataset_status_label.configure(
                        text=f"Using most recent: {os.path.basename(project)}",
                        text_color="#E67E22")
                else:
                    self.dataset_status_label.configure(
                        text="No project found",
                        text_color="#E74C3C")
                    showerror("Error", "No project selected and no projects found.")
                    return
            else:
                self.dataset_status_label.configure(
                    text="No project found",
                    text_color="#E74C3C")
                showerror("Error", "No project selected.")
                return
        
        # Validate dataset
        is_valid, status = validate_dataset(project)
        
        # Update status label
        if is_valid:
            status_text = (f"‚úì Dataset valid\n"
                          f"Images: {status['image_count']} | "
                          f"Annotations: {status['valid_annotations']} | "
                          f"Classes: {len(status['classes'])}")
            self.dataset_status_label.configure(text=status_text, text_color="#2ECC71")
            
            # Show detailed info
            detail_msg = (f"Dataset Validation: PASSED ‚úì\n\n"
                         f"Project: {os.path.basename(project)}\n"
                         f"Images: {status['image_count']}\n"
                         f"Annotated: {status['valid_annotations']}\n"
                         f"Classes: {len(status['classes'])}\n"
                         f"  {', '.join(sorted(status['classes']))}\n")
            
            if status['warnings']:
                detail_msg += f"\nWarnings ({len(status['warnings'])}):\n"
                for warning in status['warnings'][:5]:
                    detail_msg += f"  ‚Ä¢ {warning}\n"
            
            detail_msg += "\nDataset is ready for training!"
            showinfo("Dataset Validation", detail_msg)
            
        else:
            status_text = f"‚úó Validation failed"
            self.dataset_status_label.configure(text=status_text, text_color="#E74C3C")
            
            # Show errors
            error_msg = (f"Dataset Validation: FAILED ‚úó\n\n"
                        f"Project: {os.path.basename(project)}\n\n"
                        f"Errors:\n")
            for error in status['errors']:
                error_msg += f"  ‚Ä¢ {error}\n"
            
            if status['warnings']:
                error_msg += f"\nWarnings:\n"
                for warning in status['warnings'][:5]:
                    error_msg += f"  ‚Ä¢ {warning}\n"
            
            error_msg += f"\nDataset path: {project}"
            showerror("Dataset Validation Failed", error_msg)
    
    def train_model_thread(self):
        # Allow training even without current project - will auto-select
        t = threading.Thread(target=self.train_model)
        t.daemon = True
        t.start()

    def train_model(self):
        self.train_status_label.configure(text="Initializing training...", text_color="#4A90E2")
        self.progress_bar.set(0)
        
        try:
            # Auto-select most recent project if none selected
            project_to_train = self.current_project
            if not project_to_train:
                # Try to find the most recent project
                if os.path.exists(PROJECTS_FOLDER):
                    projects = [os.path.join(PROJECTS_FOLDER, d) 
                               for d in os.listdir(PROJECTS_FOLDER) 
                               if os.path.isdir(os.path.join(PROJECTS_FOLDER, d))]
                    if projects:
                        # Sort by modification time (most recent first)
                        projects.sort(key=lambda p: os.path.getmtime(p), reverse=True)
                        project_to_train = projects[0]
                        self.log_metric(f"No project selected. Auto-selected most recent: {os.path.basename(project_to_train)}")
                        
                        # Ask user if they want to use this project
                        if not askyesno("Auto-Select Project", 
                                       f"No project selected. Use most recent project?\n\n"
                                       f"Project: {os.path.basename(project_to_train)}"):
                            raise ValueError("No project selected for training.")
                    else:
                        raise ValueError("No project selected and no projects found.")
                else:
                    raise ValueError("No project selected for training.")
            
            # Validate dataset before training
            self.log_metric("Validating dataset...")
            is_valid, status = validate_dataset(project_to_train)
            
            if not is_valid:
                error_msg = "Dataset validation failed:\n\n"
                for error in status["errors"]:
                    error_msg += f"  ‚Ä¢ {error}\n"
                    self.log_metric(f"ERROR: {error}")
                
                if status["warnings"]:
                    error_msg += "\nWarnings:\n"
                    for warning in status["warnings"][:3]:
                        error_msg += f"  ‚Ä¢ {warning}\n"
                        self.log_metric(f"WARNING: {warning}")
                
                error_msg += f"\nDataset path: {project_to_train}"
                raise ValueError(error_msg)
            
            self.log_metric(f"‚úì Dataset validation passed")
            self.log_metric(f"  Images: {status['image_count']}")
            self.log_metric(f"  Valid annotations: {status['valid_annotations']}")
            self.log_metric(f"  Classes: {len(status['classes'])} - {sorted(status['classes'])}")
            
            # Get hyperparameters
            epochs = int(self.epochs_entry.get() or 10)
            lr = float(self.lr_entry.get() or 0.005)
            batch_size = int(self.batch_entry.get() or 2)
            momentum = float(self.momentum_entry.get() or 0.9)
            weight_decay = float(self.weight_decay_entry.get() or 0.0005)
            
            # Log comprehensive CUDA diagnostics at training start
            self.log_metric("=" * 60)
            self.log_metric("TRAINING STARTED - CUDA Diagnostics")
            self.log_metric("=" * 60)
            diagnostics = get_cuda_diagnostics()
            self.log_metric(f"PyTorch version: {diagnostics['torch_version']}")
            self.log_metric(f"CUDA version: {diagnostics['cuda_version']}")
            self.log_metric(f"CUDA available: {diagnostics['cuda_available']}")
            self.log_metric(f"CUDA device count: {diagnostics['device_count']}")
            if diagnostics['device_name']:
                self.log_metric(f"Device name: {diagnostics['device_name']}")
            self.log_metric(f"CUDA_VISIBLE_DEVICES: {diagnostics['cuda_visible_devices']}")
            
            # Get device based on preference
            device, device_name = self.get_training_device()
            
            self.log_metric("=" * 60)
            self.log_metric(f"Starting training with {epochs} epochs")
            self.log_metric(f"Learning rate: {lr}, Batch size: {batch_size}")
            self.log_metric(f"Using device: {device_name} (preference: {self.device_preference})")
            self.log_metric("-" * 50)
            self.show_notification(f"üöÄ Training started on {device_name}", "info")
            
            classes_path = os.path.join(project_to_train, "classes.txt")
            if not os.path.exists(classes_path):
                raise ValueError(f"Classes file not found: {classes_path}")
            
            with open(classes_path, "r") as f:
                classes = [line.strip() for line in f if line.strip()]
            if not classes:
                raise ValueError("No classes defined in classes.txt")
            class_to_id = {c: i+1 for i, c in enumerate(classes)}
            num_classes = len(classes) + 1

            dataset = AnnotationDataset(project_to_train, class_to_id)
            # Filter None
            data = [d for d in dataset if d[0] is not None]
            if not data:
                raise ValueError(f"No valid annotated images found in {project_to_train}.\n"
                               f"Expected format: images in 'images/' folder, annotations in 'annotations/' folder.")
            
            self.log_metric(f"Loaded {len(data)} annotated images from {len(dataset)} total images")
            dataloader = DataLoader(data, batch_size=batch_size, shuffle=True, 
                                  collate_fn=lambda x: tuple(zip(*x)))

            model = fasterrcnn_resnet50_fpn(weights=None, num_classes=num_classes)
            model.to(device)

            params = [p for p in model.parameters() if p.requires_grad]
            optimizer = torch.optim.SGD(params, lr=lr, momentum=momentum, weight_decay=weight_decay)

            for epoch in range(epochs):
                model.train()
                epoch_losses = []
                
                for batch_idx, (images, targets) in enumerate(dataloader):
                    images = list(image.to(device) for image in images)
                    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
                    loss_dict = model(images, targets)
                    losses = sum(loss for loss in loss_dict.values())
                    
                    optimizer.zero_grad()
                    losses.backward()
                    optimizer.step()
                    
                    epoch_losses.append(losses.item())
                
                avg_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else 0
                progress = (epoch + 1) / epochs
                self.progress_bar.set(progress)
                self.progress_label.configure(text=f"{int(progress * 100)}%")
                self.train_status_label.configure(text=f"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}", 
                                                 text_color="#E67E22")
                self.log_metric(f"Epoch {epoch+1}/{epochs} - Avg Loss: {avg_loss:.4f}")

            model_path = os.path.join(project_to_train, "model.pth")
            torch.save(model.state_dict(), model_path)
            self.log_metric("-" * 50)
            self.log_metric(f"Model saved to: {model_path}")

            project_name = os.path.basename(project_to_train)
            self.generate_recognizer(project_name, model_path, classes)
            self.reload_recognizers()
            
            # Auto-select the newly trained recognizer
            self.selected_recognizer.set(project_name)
            self.show_notification(f"‚úì Model '{project_name}' selected for recognition", "success")

            self.progress_bar.set(1.0)
            self.progress_label.configure(text="100%")
            self.train_status_label.configure(text="‚úì Training Complete!", text_color="green")
            self.log_metric("Training completed successfully!")
            showinfo("Training Complete", "Model trained successfully!")
            
        except Exception as e:
            self.log_metric(f"ERROR: {str(e)}")
            showerror("Training Error", str(e))
            self.train_status_label.configure(text="‚úó Training Failed", text_color="red")
            self.progress_bar.set(0)

    def log_metric(self, message):
        """Log training metrics to text widget"""
        if hasattr(self, 'metrics_text'):
            self.metrics_text.config(state="normal")
            self.metrics_text.insert(tk.END, f"{message}\n")
            self.metrics_text.see(tk.END)
            self.metrics_text.config(state="disabled")

    def generate_recognizer(self, project_name, model_path, classes):
        code = f"""
import torch
import torchvision
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.transforms import functional as F
import numpy as np
from PIL import Image

class Recognizer:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.num_classes = {len(classes) + 1}
        self.model = fasterrcnn_resnet50_fpn(weights=None, num_classes=self.num_classes)
        self.model.load_state_dict(torch.load(r'{model_path}', weights_only=True, map_location=self.device))
        self.model.to(self.device)
        self.model.eval()
        self.classes = {classes}

    def recognize(self, image_np):
        img = Image.fromarray(image_np).convert('RGB')
        img_t = F.to_tensor(img).to(self.device)
        with torch.no_grad():
            outputs = self.model([img_t])[0]
        results = []
        for i in range(len(outputs['boxes'])):
            score = outputs['scores'][i].item()
            if score > 0.5:
                label_id = outputs['labels'][i].item()
                label = self.classes[label_id - 1] if 1 <= label_id <= len(self.classes) else 'Unknown'
                box = outputs['boxes'][i].cpu().numpy().tolist()
                results.append({{'box': box, 'label': label, 'score': score}})
        return results
"""
        rec_path = os.path.join(RECOGNIZER_FOLDER, f"{project_name}.py")
        with open(rec_path, "w") as f:
            f.write(code)

    def reload_recognizers(self):
        self.recognizer_manager = RecognizerManager(RECOGNIZER_FOLDER)
        names = self.recognizer_manager.get_names()
        self.recognizer_menu.configure(values=names)
        if names:
            self.selected_recognizer.set(names[0])

    # Recognize tab functions
    def rec_on_canvas_resize(self, event):
        if self.rec_last_image is not None:
            self.rec_display_image_with_boxes(self.rec_last_image, self.rec_last_results, self.highlighted_box_idx)

    def rec_capture_and_recognize_thread(self):
        names = self.recognizer_manager.get_names()
        if not names:
            showerror("Error", "No recognizers available. Train a model first.")
            return
        t = threading.Thread(target=self.rec_capture_and_recognize)
        t.daemon = True
        t.start()

    def rec_capture_and_recognize(self):
        self.rec_status_label.configure(text="Capturing...", text_color="#4A90E2")
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            sct_img = sct.grab(monitor)
            img = Image.frombytes("RGB", sct_img.size, sct_img.bgra, "raw", "BGRX")
        img_np = np.array(img)
        self.rec_status_label.configure(text="Recognizing...", text_color="#E67E22")
        rec_name = self.selected_recognizer.get()
        results_raw = self.recognizer_manager.recognize(rec_name, img_np)
        
        # Store raw results and apply filtering
        self.rec_last_results_raw = results_raw
        results = self.filter_detections(results_raw)
        
        self.rec_last_image = img
        self.rec_last_results = results
        self.rec_display_image_with_boxes(img, results, None)
        self.rec_result_panel.update_results(results)
        self.rec_status_label.configure(text=f"Done - {len(results)} detections", text_color="green")

    def rec_display_image_with_boxes(self, pil_image, results, highlight_idx):
        w, h = self.rec_canvas.winfo_width(), self.rec_canvas.winfo_height()
        if w < 10 or h < 10:
            return
        aspect_ratio = pil_image.width / pil_image.height
        canvas_ratio = w / h
        if aspect_ratio > canvas_ratio:
            new_w = w
            new_h = int(w / aspect_ratio)
        else:
            new_h = h
            new_w = int(h * aspect_ratio)
        img = pil_image.copy().resize((new_w, new_h), Image.LANCZOS)
        draw = ImageDraw.Draw(img, "RGBA")
        font = load_font(size=max(14, new_h//32))
        for idx, res in enumerate(results):
            box = res.get("box")
            label = res.get("label", "Unknown")
            score = res.get("score", None)
            if not box: continue
            color = BOX_COLORS[idx % len(BOX_COLORS)]
            if highlight_idx == idx:
                outline = (255,255,255,255)
                width = 5
            else:
                outline = color
                width = 3
            x1, y1, x2, y2 = [int(a * new_w / pil_image.width) for a in box]
            draw.rounded_rectangle([x1, y1, x2, y2], radius=8, outline=outline, width=width, fill=color+"40")
            lbl = label
            if score is not None:
                lbl += f" ({score*100:.1f}%)"
            bbox = draw.textbbox((0, 0), lbl, font=font)
            text_w = bbox[2] - bbox[0]
            text_h = bbox[3] - bbox[1]
            draw.rectangle([x1, y1 - text_h - 8, x1 + text_w + 10, y1], fill=color+"C0", outline=None)
            draw.text((x1+5, y1-text_h-4), lbl, fill="white", font=font)
        tk_img = ImageTk.PhotoImage(img)
        self.rec_canvas.delete("all")
        self.rec_image_on_canvas = tk_img
        self.rec_canvas.create_image(w//2, h//2, anchor="center", image=tk_img)

    def rec_highlight_box(self, idx):
        self.highlighted_box_idx = idx
        if self.rec_last_image is not None:
            self.rec_display_image_with_boxes(self.rec_last_image, self.rec_last_results, idx)

    def rec_save_image(self):
        if self.rec_last_image is None:
            return
        f = filedialog.asksaveasfilename(defaultextension=".png", filetypes=[("PNG","*.png")])
        if not f: return
        img = self.rec_last_image.copy()
        draw = ImageDraw.Draw(img, "RGBA")
        font = load_font(size=18)
        for idx, res in enumerate(self.rec_last_results):
            box = res.get("box")
            label = res.get("label", "Unknown")
            score = res.get("score", None)
            if not box: continue
            color = BOX_COLORS[idx % len(BOX_COLORS)]
            x1, y1, x2, y2 = box
            draw.rounded_rectangle([x1, y1, x2, y2], radius=8, outline=color, width=4, fill=color+"40")
            lbl = label
            if score is not None:
                lbl += f" ({score*100:.1f}%)"
            bbox = draw.textbbox((0,0), lbl, font=font)
            text_w = bbox[2] - bbox[0]
            text_h = bbox[3] - bbox[1]
            draw.rectangle([x1, y1 - text_h - 8, x1 + text_w + 10, y1], fill=color+"C0", outline=None)
            draw.text((x1+5, y1-text_h-4), lbl, fill="white", font=font)
        img.save(f)
        self.rec_status_label.configure(text="Saved!", text_color="#27AE60")

    def rec_copy_labels(self):
        if not self.rec_last_results:
            return
        s = "\n".join([f"{r.get('label', 'Unknown')} ({r.get('score', 0)*100:.1f}%)" if "score" in r else r.get('label', 'Unknown') for r in self.rec_last_results])
        self.clipboard_clear()
        self.clipboard_append(s)
        self.rec_status_label.configure(text="Labels Copied!", text_color="#27AE60")
    
    def toggle_live_mode(self):
        """Toggle live recognition mode"""
        if self.live_mode_var.get():
            self.start_live_recognition()
        else:
            self.stop_live_recognition()
    
    def update_fps(self, value):
        """Update FPS for live recognition"""
        self.live_fps = int(float(value))
        self.fps_label.configure(text=f"{self.live_fps}")
    
    def start_live_recognition(self):
        """Start live recognition mode"""
        names = self.recognizer_manager.get_names()
        if not names:
            showerror("Error", "No recognizers available. Train a model first.")
            self.live_mode_var.set(False)
            return
        
        self.live_recognition_active = True
        self.rec_capture_button.configure(state="disabled")
        self.show_notification(f"üé• Live recognition running ‚Äî {self.live_fps} FPS", "info")
        
        # Start capture thread
        self.live_capture_thread = threading.Thread(target=self.live_recognition_loop, daemon=True)
        self.live_capture_thread.start()
    
    def stop_live_recognition(self):
        """Stop live recognition mode"""
        self.live_recognition_active = False
        self.rec_capture_button.configure(state="normal")
        self.show_notification("Live recognition stopped", "info")
    
    def live_recognition_loop(self):
        """Continuous capture and recognition loop"""
        rec_name = self.selected_recognizer.get()
        
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            
            while self.live_recognition_active:
                start_time = time.time()
                
                try:
                    # Capture screen
                    sct_img = sct.grab(monitor)
                    img = Image.frombytes("RGB", sct_img.size, sct_img.bgra, "raw", "BGRX")
                    img_np = np.array(img)
                    
                    # Recognize
                    results_raw = self.recognizer_manager.recognize(rec_name, img_np)
                    self.rec_last_results_raw = results_raw
                    results = self.filter_detections(results_raw)
                    
                    # Update display
                    self.rec_last_image = img
                    self.rec_last_results = results
                    self.rec_display_image_with_boxes(img, results, None)
                    self.rec_result_panel.update_results(results)
                    self.rec_status_label.configure(text=f"Live: {len(results)} detections", 
                                                   text_color="green")
                    
                except Exception as e:
                    print(f"Error in live recognition: {e}")
                
                # Sleep to maintain FPS
                elapsed = time.time() - start_time
                sleep_time = max(0, (1.0 / self.live_fps) - elapsed)
                time.sleep(sleep_time)
    
    def rec_save_images_with_annotations(self):
        """Save detected images with annotations in COCO or per-image JSON format"""
        if self.rec_last_image is None:
            showerror("Error", "No image to save. Capture or run recognition first.")
            return
        
        if not self.rec_last_results:
            if not askyesno("No Detections", "No detections found. Save image anyway?"):
                return
        
        # Create export directory
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        export_dir = os.path.join("exports", f"recognition_{timestamp}")
        images_dir = os.path.join(export_dir, "images")
        annotations_dir = os.path.join(export_dir, "annotations")
        
        try:
            os.makedirs(images_dir, exist_ok=True)
            os.makedirs(annotations_dir, exist_ok=True)
            
            format_type = self.save_format_var.get()
            
            if self.live_recognition_active:
                # Save multiple frames from live mode
                try:
                    num_frames = int(self.frames_entry.get() or 10)
                except ValueError:
                    num_frames = 10
                
                self.save_live_frames(images_dir, annotations_dir, num_frames, format_type)
            else:
                # Save single image
                self.save_single_detection(images_dir, annotations_dir, format_type, timestamp)
            
            # Validate and register dataset
            self.show_notification("Validating dataset...", "info")
            is_valid, status = validate_dataset(export_dir)
            
            if is_valid:
                # Ask user if they want to register this dataset for training
                register_msg = (f"Dataset exported successfully!\n\n"
                              f"Images: {status['image_count']}\n"
                              f"Valid annotations: {status['valid_annotations']}\n"
                              f"Classes: {len(status['classes'])}\n\n"
                              f"Would you like to register this dataset as a project for training?")
                
                if askyesno("Register Dataset", register_msg):
                    project_name = f"exported_{timestamp}"
                    success, project_path, msg = register_dataset_as_project(export_dir, project_name)
                    
                    if success:
                        self.show_notification(f"‚úì Dataset registered: {project_name}", "success")
                        # Offer to switch to this project
                        if askyesno("Switch Project", 
                                   f"Dataset registered as project '{project_name}'.\n\n"
                                   f"Would you like to switch to this project now?"):
                            self.load_project(project_path)
                            self.show_notification(f"‚úì Switched to {project_name}", "success")
                        
                        showinfo("Success", msg)
                    else:
                        showerror("Registration Failed", msg)
                        self.show_notification("‚úó Dataset registration failed", "error")
                else:
                    showinfo("Export Complete", 
                            f"Images and annotations saved successfully!\n\n"
                            f"Location: {os.path.abspath(export_dir)}\n"
                            f"Format: {format_type}\n"
                            f"Images: {len(os.listdir(images_dir))}\n"
                            f"Note: Dataset not registered for training")
            else:
                # Show validation errors
                error_msg = "Dataset exported but validation failed:\n\n"
                for error in status["errors"][:5]:
                    error_msg += f"  ‚Ä¢ {error}\n"
                if status["warnings"]:
                    error_msg += "\nWarnings:\n"
                    for warning in status["warnings"][:3]:
                        error_msg += f"  ‚Ä¢ {warning}\n"
                error_msg += f"\nLocation: {os.path.abspath(export_dir)}"
                
                showerror("Validation Issues", error_msg)
                self.show_notification("‚ö†Ô∏è Dataset exported but has validation issues", "warning")
            
        except Exception as e:
            showerror("Save Error", f"Failed to save: {str(e)}")
            self.show_notification(f"‚úó Save failed: {str(e)}", "error")
    
    def save_single_detection(self, images_dir, annotations_dir, format_type, timestamp):
        """Save a single detection result"""
        # Save image
        img_filename = f"detection_{timestamp}.png"
        img_path = os.path.join(images_dir, img_filename)
        self.rec_last_image.save(img_path)
        
        # Save annotations
        if format_type == "COCO JSON":
            self.save_coco_json(images_dir, annotations_dir, 
                              [(img_filename, self.rec_last_image, self.rec_last_results)])
        else:  # Per-image JSON
            ann_filename = f"detection_{timestamp}.json"
            ann_path = os.path.join(annotations_dir, ann_filename)
            self.save_per_image_json(ann_path, img_filename, self.rec_last_image, 
                                    self.rec_last_results, timestamp)
    
    def save_live_frames(self, images_dir, annotations_dir, num_frames, format_type):
        """Save multiple frames from live recognition"""
        saved_frames = []
        rec_name = self.selected_recognizer.get()
        
        self.show_notification(f"Capturing {num_frames} frames...", "info")
        
        with mss.mss() as sct:
            monitor = sct.monitors[1]
            
            for i in range(num_frames):
                if not self.live_recognition_active:
                    break
                
                # Capture and recognize
                sct_img = sct.grab(monitor)
                img = Image.frombytes("RGB", sct_img.size, sct_img.bgra, "raw", "BGRX")
                img_np = np.array(img)
                
                results_raw = self.recognizer_manager.recognize(rec_name, img_np)
                results = self.filter_detections(results_raw)
                
                # Save image
                timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S-%f")[:-3]
                img_filename = f"frame_{i:04d}_{timestamp}.png"
                img_path = os.path.join(images_dir, img_filename)
                img.save(img_path)
                
                saved_frames.append((img_filename, img, results))
                
                # Small delay between captures
                time.sleep(1.0 / self.live_fps)
        
        # Save annotations
        if format_type == "COCO JSON":
            self.save_coco_json(images_dir, annotations_dir, saved_frames)
        else:  # Per-image JSON
            for img_filename, img, results in saved_frames:
                timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
                ann_filename = os.path.splitext(img_filename)[0] + ".json"
                ann_path = os.path.join(annotations_dir, ann_filename)
                self.save_per_image_json(ann_path, img_filename, img, results, timestamp)
    
    def save_coco_json(self, images_dir, annotations_dir, frames_data):
        """Save annotations in COCO JSON format"""
        coco_data = {
            "info": {
                "description": "Image Recognition Detections",
                "version": "1.0",
                "year": datetime.now().year,
                "date_created": datetime.now().isoformat()
            },
            "images": [],
            "annotations": [],
            "categories": []
        }
        
        # Collect unique categories
        categories_set = set()
        for _, _, results in frames_data:
            for res in results:
                categories_set.add(res.get('label', 'Unknown'))
        
        # Add categories
        category_to_id = {}
        for idx, cat_name in enumerate(sorted(categories_set), start=1):
            coco_data["categories"].append({
                "id": idx,
                "name": cat_name,
                "supercategory": "object"
            })
            category_to_id[cat_name] = idx
        
        # Add images and annotations
        annotation_id = 1
        for image_id, (img_filename, img, results) in enumerate(frames_data, start=1):
            # Add image
            coco_data["images"].append({
                "id": image_id,
                "file_name": img_filename,
                "width": img.width,
                "height": img.height,
                "date_captured": datetime.now().isoformat()
            })
            
            # Add annotations for this image
            for res in results:
                box = res.get('box')
                if not box:
                    continue
                
                x1, y1, x2, y2 = box
                width = x2 - x1
                height = y2 - y1
                
                annotation = {
                    "id": annotation_id,
                    "image_id": image_id,
                    "category_id": category_to_id.get(res.get('label', 'Unknown'), 1),
                    "bbox": [x1, y1, width, height],  # COCO format: [x, y, width, height]
                    "area": width * height,
                    "iscrowd": 0
                }
                
                if 'score' in res:
                    annotation['score'] = res['score']
                
                coco_data["annotations"].append(annotation)
                annotation_id += 1
        
        # Save COCO JSON
        coco_path = os.path.join(annotations_dir, "instances.json")
        with open(coco_path, 'w') as f:
            json.dump(coco_data, f, indent=2)
    
    def save_per_image_json(self, ann_path, img_filename, img, results, timestamp):
        """Save annotations in per-image JSON format"""
        data = {
            "image": img_filename,
            "width": img.width,
            "height": img.height,
            "timestamp": timestamp,
            "source": "screen_capture",
            "detections": []
        }
        
        for res in results:
            detection = {
                "label": res.get('label', 'Unknown'),
                "box": res.get('box'),
                "confidence": res.get('score')
            }
            data["detections"].append(detection)
        
        with open(ann_path, 'w') as f:
            json.dump(data, f, indent=2)

if __name__ == "__main__":
    app = ImageRecognitionApp()
    app.mainloop()